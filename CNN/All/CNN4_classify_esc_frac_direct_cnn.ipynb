{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras is using tensorflow as the backend\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import sklearn\n",
    "import random\n",
    "import os,sys\n",
    "\n",
    "# import keras\n",
    "import keras\n",
    "from keras import backend as K\n",
    "backend_keras = keras.backend.backend()\n",
    "print(\"keras is using\", backend_keras, \"as the backend\")\n",
    "from keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.optimizers import SGD, Nadam, Adamax, Adam, Adadelta, Adagrad, RMSprop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load redshift data and labels\n",
    "These are the ones which have been created with the keras notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints\n",
      "CNN3_classify_redshift_with_autoencoder.ipynb\n",
      "CNN4_classify_esc_frac_direct_cnn.ipynb\n",
      "CNN5_classify_esc_frac_with_autoencoder.ipynb\n",
      "CNN6_classify_redshift_direct_cnn.ipynb\n",
      "big_mix_data_6528.npy\n",
      "big_mix_labels_6528.npy\n",
      "data_test.npy\n",
      "data_train.npy\n",
      "data_val.npy\n",
      "figures\n",
      "keras_arch_05.0_with_encoder_esc_predict.model\n",
      "keras_arch_05.1_with_encoder_esc_predict.model\n",
      "keras_arch_05.2_with_encoder_esc_predict.model\n",
      "keras_arch_05.3_with_encoder_esc_predict.model\n",
      "keras_arch_05.4.5_with_encoder_esc_predict.model\n",
      "keras_arch_05.4.75_with_encoder_esc_predict.model\n",
      "keras_arch_05.4_with_encoder_esc_predict.model\n",
      "labels_test.npy\n",
      "labels_train.npy\n",
      "labels_val.npy\n",
      "preprocessing.ipynb\n",
      "trained models\n",
      "training_perf_250_arch_03.0_pred_redshift_with_encoder.png\n"
     ]
    }
   ],
   "source": [
    "f = os.listdir()\n",
    "f.sort()\n",
    "for i in f: print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes : (4896, 200, 200, 1) (652, 200, 200, 1) (980, 200, 200, 1)\n",
      "more shape : (4896, 12) (652, 12) (980, 12)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "x_train_raw = np.load(\"data_train.npy\",allow_pickle=True)\n",
    "x_val_raw = np.load(\"data_val.npy\")\n",
    "x_test_raw = np.load(\"data_test.npy\")\n",
    "\n",
    "# load labels\n",
    "labels_train = np.load(\"labels_train.npy\",allow_pickle=True)\n",
    "labels_val = np.load(\"labels_val.npy\",allow_pickle=True)\n",
    "labels_test = np.load(\"labels_test.npy\",allow_pickle=True)\n",
    "\n",
    "# we only care about the redshift labels here\n",
    "lab_esc_train = np.array([i[0] for i in labels_train])\n",
    "lab_esc_val = np.array([i[0] for i in labels_val])\n",
    "lab_esc_test = np.array([i[0] for i in labels_test])\n",
    "\n",
    "print(\"shapes :\", x_train_raw.shape, x_val_raw.shape, x_test_raw.shape)\n",
    "print(\"more shape :\", lab_esc_train.shape, lab_esc_val.shape, lab_esc_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train_raw\n",
    "x_val = x_val_raw\n",
    "x_test = x_test_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "# extract features\n",
    "classifier.add(Conv2D(16, (3,3), input_shape=(200,200,1),\n",
    "                     activation='relu', padding='valid'))\n",
    "# reduce dimensionality, keep most important info\n",
    "classifier.add(MaxPooling2D(pool_size=(3,3)))\n",
    "\n",
    "# add a second layer, again with no padding\n",
    "classifier.add(Conv2D(8, (3,3), activation='relu', padding='valid'))\n",
    "\n",
    "# pool again\n",
    "classifier.add(MaxPooling2D(pool_size=(3,3)))\n",
    "\n",
    "# here i flatten and then guess the class\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# fully connected layers ensures connections to all activations \n",
    "# in previous layers\n",
    "\n",
    "classifier.add(Dense(units=12, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper params + compile network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing summary of model\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 198, 198, 16)      160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 66, 66, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 64, 64, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 21, 21, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 3528)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 12)                42348     \n",
      "=================================================================\n",
      "Total params: 43,668\n",
      "Trainable params: 43,668\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# SGD, Nadam, Adamax, Adam, Adadelta, Adagrad, RMSprop\n",
    "\n",
    "opt = RMSprop(learning_rate=0.001, rho=0.9)\n",
    "\n",
    "classifier.compile(optimizer=opt,\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=[\"accuracy\"])\n",
    "print(\"printing summary of model\")\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4896, 200, 200, 1) (4896, 12)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, lab_esc_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4896 samples, validate on 652 samples\n",
      "Epoch 1/50\n",
      "4896/4896 [==============================] - 59s 12ms/step - loss: 2.4837 - accuracy: 0.0778 - val_loss: 2.4836 - val_accuracy: 0.0675\n",
      "Epoch 2/50\n",
      "4896/4896 [==============================] - 59s 12ms/step - loss: 2.4807 - accuracy: 0.0854 - val_loss: 2.4838 - val_accuracy: 0.0813\n",
      "Epoch 3/50\n",
      "4896/4896 [==============================] - 59s 12ms/step - loss: 2.4785 - accuracy: 0.0956 - val_loss: 2.4847 - val_accuracy: 0.0613\n",
      "Epoch 4/50\n",
      "4896/4896 [==============================] - 60s 12ms/step - loss: 2.4758 - accuracy: 0.1001 - val_loss: 2.4877 - val_accuracy: 0.0936\n",
      "Epoch 5/50\n",
      "4896/4896 [==============================] - 62s 13ms/step - loss: 2.4719 - accuracy: 0.1054 - val_loss: 2.4924 - val_accuracy: 0.0629\n",
      "Epoch 6/50\n",
      "4896/4896 [==============================] - 59s 12ms/step - loss: 2.4671 - accuracy: 0.1103 - val_loss: 2.5051 - val_accuracy: 0.0690\n",
      "Epoch 7/50\n",
      "4896/4896 [==============================] - 60s 12ms/step - loss: 2.4616 - accuracy: 0.1189 - val_loss: 2.5096 - val_accuracy: 0.0767\n",
      "Epoch 8/50\n",
      "4896/4896 [==============================] - 61s 12ms/step - loss: 2.4562 - accuracy: 0.1258 - val_loss: 2.5030 - val_accuracy: 0.0920\n",
      "Epoch 9/50\n",
      "4896/4896 [==============================] - 63s 13ms/step - loss: 2.4491 - accuracy: 0.1293 - val_loss: 2.5555 - val_accuracy: 0.1074\n",
      "Epoch 10/50\n",
      "4896/4896 [==============================] - 63s 13ms/step - loss: 2.4428 - accuracy: 0.1287 - val_loss: 2.5343 - val_accuracy: 0.1104\n",
      "Epoch 11/50\n",
      "4896/4896 [==============================] - 64s 13ms/step - loss: 2.4336 - accuracy: 0.1464 - val_loss: 2.5243 - val_accuracy: 0.0736\n",
      "Epoch 12/50\n",
      "4896/4896 [==============================] - 63s 13ms/step - loss: 2.4258 - accuracy: 0.1485 - val_loss: 2.5322 - val_accuracy: 0.0782\n",
      "Epoch 13/50\n",
      "4896/4896 [==============================] - 63s 13ms/step - loss: 2.4140 - accuracy: 0.1550 - val_loss: 2.5387 - val_accuracy: 0.0859\n",
      "Epoch 14/50\n",
      "4896/4896 [==============================] - 63s 13ms/step - loss: 2.4061 - accuracy: 0.1626 - val_loss: 2.5421 - val_accuracy: 0.0629\n",
      "Epoch 15/50\n",
      "4896/4896 [==============================] - 65s 13ms/step - loss: 2.3948 - accuracy: 0.1673 - val_loss: 2.5935 - val_accuracy: 0.0690\n",
      "Epoch 16/50\n",
      "4896/4896 [==============================] - 64s 13ms/step - loss: 2.3833 - accuracy: 0.1730 - val_loss: 2.5821 - val_accuracy: 0.0583\n",
      "Epoch 17/50\n",
      "4896/4896 [==============================] - 63s 13ms/step - loss: 2.3765 - accuracy: 0.1828 - val_loss: 2.5603 - val_accuracy: 0.0736\n",
      "Epoch 18/50\n",
      "4896/4896 [==============================] - 63s 13ms/step - loss: 2.3590 - accuracy: 0.1932 - val_loss: 2.6538 - val_accuracy: 0.1242\n",
      "Epoch 19/50\n",
      "4896/4896 [==============================] - 62s 13ms/step - loss: 2.3501 - accuracy: 0.1806 - val_loss: 2.6536 - val_accuracy: 0.0798\n",
      "Epoch 20/50\n",
      "4896/4896 [==============================] - 63s 13ms/step - loss: 2.3398 - accuracy: 0.1946 - val_loss: 2.5705 - val_accuracy: 0.0706\n",
      "Epoch 21/50\n",
      "4896/4896 [==============================] - 71s 14ms/step - loss: 2.3273 - accuracy: 0.1969 - val_loss: 2.6159 - val_accuracy: 0.0414\n",
      "Epoch 22/50\n",
      "3200/4896 [==================>...........] - ETA: 21s - loss: 2.3058 - accuracy: 0.2091"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "H = classifier.fit(x_train, lab_esc_train,\n",
    "                  epochs = EPOCHS,\n",
    "                  batch_size = 128,\n",
    "                  shuffle = True,\n",
    "                  validation_data=(x_val, lab_esc_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy for each epoch\n",
    "N = np.arange(0, EPOCHS)\n",
    "plt.figure()\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(N, H.history[\"accuracy\"], label=\"train_accuracy\")\n",
    "plt.plot(N, H.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.title(\"Predicting Redshift model 2\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(\"training_perf_arch_03.5_pred_esc_no_encoder.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save(\"keras_arch_05.5_with_encoder_esc_predict.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display netowrk stats and save plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OR load trained CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
