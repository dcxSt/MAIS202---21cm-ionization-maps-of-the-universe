{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras is using tensorflow as the backend\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import sklearn\n",
    "import random\n",
    "import os,sys\n",
    "\n",
    "# import keras\n",
    "import keras\n",
    "from keras import backend as K\n",
    "backend_keras = keras.backend.backend()\n",
    "print(\"keras is using\", backend_keras, \"as the backend\")\n",
    "from keras.layers import Input, Flatten, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model, load_model, Sequential\n",
    "\n",
    "# opt\n",
    "from keras.optimizers import SGD, Nadam, Adamax, Adam, Adadelta, Adagrad, RMSprop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load esc frac data and labels\n",
    "These are the ones which have been created with the keras notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints\n",
      "CNN3_classify_redshift_with_autoencoder.ipynb\n",
      "CNN4_classify_esc_frac_direct_cnn.ipynb\n",
      "CNN5_classify_esc_frac_with_autoencoder.ipynb\n",
      "CNN6_classify_redshift_direct_cnn.ipynb\n",
      "big_mix_data_6528.npy\n",
      "big_mix_labels_6528.npy\n",
      "data_test.npy\n",
      "data_train.npy\n",
      "data_val.npy\n",
      "figures\n",
      "keras_arch_05.0_with_encoder_esc_predict.model\n",
      "keras_arch_05.1_with_encoder_esc_predict.model\n",
      "labels_test.npy\n",
      "labels_train.npy\n",
      "labels_val.npy\n",
      "preprocessing.ipynb\n",
      "trained models\n",
      "training_perf_250_arch_03.0_pred_redshift_with_encoder.png\n",
      "training_perf_250_arch_03.1_pred_redshift_with_encoder.png\n"
     ]
    }
   ],
   "source": [
    "f = os.listdir()\n",
    "f.sort()\n",
    "for i in f: print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes : (4896, 200, 200, 1) (652, 200, 200, 1) (980, 200, 200, 1)\n",
      "more shape : (4896, 12) (652, 12) (980, 12)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "x_train_raw = np.load(\"data_train.npy\",allow_pickle=True)\n",
    "x_val_raw = np.load(\"data_val.npy\")\n",
    "x_test_raw = np.load(\"data_test.npy\")\n",
    "\n",
    "# load labels\n",
    "labels_train = np.load(\"labels_train.npy\",allow_pickle=True)\n",
    "labels_val = np.load(\"labels_val.npy\",allow_pickle=True)\n",
    "labels_test = np.load(\"labels_test.npy\",allow_pickle=True)\n",
    "\n",
    "# we only care about the redshift labels here\n",
    "lab_esc_train = np.array([i[0] for i in labels_train])\n",
    "lab_esc_val = np.array([i[0] for i in labels_val])\n",
    "lab_esc_test = np.array([i[0] for i in labels_test])\n",
    "\n",
    "print(\"shapes :\", x_train_raw.shape, x_val_raw.shape, x_test_raw.shape)\n",
    "print(\"more shape :\", lab_esc_train.shape, lab_esc_val.shape, lab_esc_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Autoencoder\n",
    "## first load the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"../../Auto-Encoder Training/\")\n",
    "autoencoder = load_model(\"../../Auto-Encoder Training/autoencoder_adam_95.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200, 200, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 200, 200, 16)      160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 100, 100, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 100, 100, 8)       1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 50, 50, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 50, 50, 8)         584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 25, 25, 8)         0         \n",
      "=================================================================\n",
      "Total params: 1,904\n",
      "Trainable params: 1,904\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#autoencoder.summary()\n",
    "encoder = Model(autoencoder.input, autoencoder.layers[-8].output)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = encoder.predict(x_train_raw)\n",
    "x_val = encoder.predict(x_val_raw)\n",
    "x_test = encoder.predict(x_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "# extract features\n",
    "classifier.add(Conv2D(8, (3,3), input_shape=(25,25,8),\n",
    "                     activation='relu', padding='valid'))\n",
    "# reduce dimensionality, keep most important info\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# add a second layer, again with no padding\n",
    "classifier.add(Conv2D(4, (3,3), activation='relu', padding='valid'))\n",
    "\n",
    "# pool again\n",
    "#classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# here i flatten and then guess the class\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# fully connected layers ensures connections to all activations \n",
    "# in previous layers\n",
    "\n",
    "classifier.add(Dense(units=12, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "# extract features\n",
    "classifier.add(Conv2D(32, (3,3), input_shape=(25,25,8),\n",
    "                     activation='relu', padding='same'))\n",
    "# reduce dimensionality, keep most important info\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# extract features\n",
    "#classifier.add(Conv2D(16, (3,3), input_shape=(25,25,8),\n",
    "                     activation=\"relu\", padding='same'))\n",
    "\n",
    "# downsample\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "\n",
    "classifier.add(Dense(units=12, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper params + compile network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing summary of model\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 23, 23, 8)         584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 11, 11, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 9, 9, 4)           292       \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 324)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 12)                3900      \n",
      "=================================================================\n",
      "Total params: 4,776\n",
      "Trainable params: 4,776\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# SGD, Nadam, Adamax, Adam, Adadelta, Adagrad, RMSprop\n",
    "\n",
    "opt = RMSprop(learning_rate=0.001, rho=0.9)\n",
    "\n",
    "classifier.compile(optimizer=opt,\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=[\"accuracy\"])\n",
    "print(\"printing summary of model\")\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4896, 25, 25, 8) (4896, 12)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, lab_esc_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display netowrk stats and save plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4896 samples, validate on 652 samples\n",
      "Epoch 1/450\n",
      "4896/4896 [==============================] - 1s 253us/step - loss: 1.9319 - accuracy: 0.2878 - val_loss: 2.3601 - val_accuracy: 0.1840\n",
      "Epoch 2/450\n",
      "4896/4896 [==============================] - 1s 254us/step - loss: 1.9310 - accuracy: 0.2947 - val_loss: 2.2678 - val_accuracy: 0.1641\n",
      "Epoch 3/450\n",
      "4896/4896 [==============================] - 1s 281us/step - loss: 1.9313 - accuracy: 0.2884 - val_loss: 2.3795 - val_accuracy: 0.1488\n",
      "Epoch 4/450\n",
      "4896/4896 [==============================] - 1s 196us/step - loss: 1.9310 - accuracy: 0.2878 - val_loss: 2.1985 - val_accuracy: 0.1764\n",
      "Epoch 5/450\n",
      "4896/4896 [==============================] - 1s 242us/step - loss: 1.9211 - accuracy: 0.3017 - val_loss: 2.4369 - val_accuracy: 0.1840\n",
      "Epoch 6/450\n",
      "4896/4896 [==============================] - 1s 231us/step - loss: 1.9419 - accuracy: 0.2857 - val_loss: 2.1936 - val_accuracy: 0.1825\n",
      "Epoch 7/450\n",
      "4896/4896 [==============================] - 2s 343us/step - loss: 1.9329 - accuracy: 0.2833 - val_loss: 2.3484 - val_accuracy: 0.1672\n",
      "Epoch 8/450\n",
      "4896/4896 [==============================] - 1s 282us/step - loss: 1.9370 - accuracy: 0.3017 - val_loss: 2.4114 - val_accuracy: 0.1610\n",
      "Epoch 9/450\n",
      "4896/4896 [==============================] - 1s 194us/step - loss: 1.9311 - accuracy: 0.2915 - val_loss: 2.2666 - val_accuracy: 0.1672\n",
      "Epoch 10/450\n",
      "4896/4896 [==============================] - 1s 167us/step - loss: 1.9403 - accuracy: 0.2915 - val_loss: 2.5059 - val_accuracy: 0.1549\n",
      "Epoch 11/450\n",
      "4896/4896 [==============================] - 1s 270us/step - loss: 1.9298 - accuracy: 0.2947 - val_loss: 2.2482 - val_accuracy: 0.1810\n",
      "Epoch 12/450\n",
      "4896/4896 [==============================] - 1s 162us/step - loss: 1.9126 - accuracy: 0.3004 - val_loss: 2.2663 - val_accuracy: 0.1825\n",
      "Epoch 13/450\n",
      "4896/4896 [==============================] - 1s 211us/step - loss: 1.9243 - accuracy: 0.2968 - val_loss: 2.2338 - val_accuracy: 0.1764\n",
      "Epoch 14/450\n",
      "4896/4896 [==============================] - 1s 263us/step - loss: 1.9238 - accuracy: 0.2976 - val_loss: 2.2575 - val_accuracy: 0.1764\n",
      "Epoch 15/450\n",
      "4896/4896 [==============================] - 1s 207us/step - loss: 1.9097 - accuracy: 0.3007 - val_loss: 2.2076 - val_accuracy: 0.1917\n",
      "Epoch 16/450\n",
      "4896/4896 [==============================] - 1s 224us/step - loss: 1.9239 - accuracy: 0.2951 - val_loss: 2.3176 - val_accuracy: 0.1733\n",
      "Epoch 17/450\n",
      "4896/4896 [==============================] - 1s 214us/step - loss: 1.9061 - accuracy: 0.3035 - val_loss: 2.2848 - val_accuracy: 0.1840\n",
      "Epoch 18/450\n",
      "4896/4896 [==============================] - 1s 208us/step - loss: 1.9117 - accuracy: 0.3037 - val_loss: 2.2959 - val_accuracy: 0.1794\n",
      "Epoch 19/450\n",
      "4896/4896 [==============================] - 1s 213us/step - loss: 1.9247 - accuracy: 0.2970 - val_loss: 2.3117 - val_accuracy: 0.1733\n",
      "Epoch 20/450\n",
      "4896/4896 [==============================] - 1s 232us/step - loss: 1.9146 - accuracy: 0.2929 - val_loss: 2.5812 - val_accuracy: 0.1365\n",
      "Epoch 21/450\n",
      "4896/4896 [==============================] - 1s 203us/step - loss: 1.9202 - accuracy: 0.2976 - val_loss: 2.3658 - val_accuracy: 0.1794\n",
      "Epoch 22/450\n",
      "4896/4896 [==============================] - 1s 227us/step - loss: 1.9336 - accuracy: 0.2955 - val_loss: 2.2072 - val_accuracy: 0.1887\n",
      "Epoch 23/450\n",
      "4896/4896 [==============================] - 1s 188us/step - loss: 1.9107 - accuracy: 0.2978 - val_loss: 2.2192 - val_accuracy: 0.1887\n",
      "Epoch 24/450\n",
      "4896/4896 [==============================] - 1s 233us/step - loss: 1.9275 - accuracy: 0.3023 - val_loss: 2.4559 - val_accuracy: 0.1672\n",
      "Epoch 25/450\n",
      "4896/4896 [==============================] - 1s 247us/step - loss: 1.9018 - accuracy: 0.3045 - val_loss: 2.2132 - val_accuracy: 0.1933\n",
      "Epoch 26/450\n",
      "4896/4896 [==============================] - 1s 242us/step - loss: 1.9187 - accuracy: 0.2953 - val_loss: 2.3465 - val_accuracy: 0.1933\n",
      "Epoch 27/450\n",
      "4896/4896 [==============================] - 1s 242us/step - loss: 1.9318 - accuracy: 0.2964 - val_loss: 2.2606 - val_accuracy: 0.1840\n",
      "Epoch 28/450\n",
      "4896/4896 [==============================] - 1s 252us/step - loss: 1.9084 - accuracy: 0.3033 - val_loss: 2.1977 - val_accuracy: 0.1933\n",
      "Epoch 29/450\n",
      "4896/4896 [==============================] - 1s 239us/step - loss: 1.9232 - accuracy: 0.2898 - val_loss: 2.2699 - val_accuracy: 0.1917\n",
      "Epoch 30/450\n",
      "4896/4896 [==============================] - 1s 239us/step - loss: 1.8971 - accuracy: 0.2996 - val_loss: 2.7318 - val_accuracy: 0.1288\n",
      "Epoch 31/450\n",
      "4896/4896 [==============================] - 1s 235us/step - loss: 1.9319 - accuracy: 0.2904 - val_loss: 2.2104 - val_accuracy: 0.1580\n",
      "Epoch 32/450\n",
      "4896/4896 [==============================] - 1s 239us/step - loss: 1.9134 - accuracy: 0.2949 - val_loss: 2.3721 - val_accuracy: 0.1718\n",
      "Epoch 33/450\n",
      "4896/4896 [==============================] - 1s 240us/step - loss: 1.9186 - accuracy: 0.2968 - val_loss: 2.3151 - val_accuracy: 0.1656\n",
      "Epoch 34/450\n",
      "4896/4896 [==============================] - 1s 235us/step - loss: 1.8978 - accuracy: 0.3084 - val_loss: 2.3281 - val_accuracy: 0.1702\n",
      "Epoch 35/450\n",
      "4896/4896 [==============================] - 1s 237us/step - loss: 1.9028 - accuracy: 0.3000 - val_loss: 2.3909 - val_accuracy: 0.1718\n",
      "Epoch 36/450\n",
      "4896/4896 [==============================] - 1s 235us/step - loss: 1.9120 - accuracy: 0.2986 - val_loss: 2.3533 - val_accuracy: 0.1687\n",
      "Epoch 37/450\n",
      "4896/4896 [==============================] - 1s 233us/step - loss: 1.9097 - accuracy: 0.2992 - val_loss: 2.1812 - val_accuracy: 0.1933\n",
      "Epoch 38/450\n",
      "4896/4896 [==============================] - 1s 236us/step - loss: 1.9198 - accuracy: 0.2984 - val_loss: 2.2325 - val_accuracy: 0.1887\n",
      "Epoch 39/450\n",
      "4896/4896 [==============================] - 1s 234us/step - loss: 1.9132 - accuracy: 0.2962 - val_loss: 2.3754 - val_accuracy: 0.1518\n",
      "Epoch 40/450\n",
      "4896/4896 [==============================] - 1s 234us/step - loss: 1.9165 - accuracy: 0.2998 - val_loss: 2.3471 - val_accuracy: 0.1580\n",
      "Epoch 41/450\n",
      "4896/4896 [==============================] - 1s 235us/step - loss: 1.8933 - accuracy: 0.3049 - val_loss: 2.1868 - val_accuracy: 0.2071\n",
      "Epoch 42/450\n",
      "4896/4896 [==============================] - 1s 236us/step - loss: 1.9124 - accuracy: 0.3025 - val_loss: 2.2666 - val_accuracy: 0.1856\n",
      "Epoch 43/450\n",
      "4896/4896 [==============================] - 1s 237us/step - loss: 1.9208 - accuracy: 0.2925 - val_loss: 2.5559 - val_accuracy: 0.1442\n",
      "Epoch 44/450\n",
      "4896/4896 [==============================] - 1s 236us/step - loss: 1.8910 - accuracy: 0.3058 - val_loss: 2.8456 - val_accuracy: 0.1304\n",
      "Epoch 45/450\n",
      "4896/4896 [==============================] - 1s 234us/step - loss: 1.9066 - accuracy: 0.3004 - val_loss: 3.3285 - val_accuracy: 0.1426\n",
      "Epoch 46/450\n",
      "4896/4896 [==============================] - 1s 233us/step - loss: 1.9503 - accuracy: 0.2908 - val_loss: 2.1776 - val_accuracy: 0.1887\n",
      "Epoch 47/450\n",
      "4896/4896 [==============================] - 1s 235us/step - loss: 1.8967 - accuracy: 0.3090 - val_loss: 2.2733 - val_accuracy: 0.1687\n",
      "Epoch 48/450\n",
      "4896/4896 [==============================] - 1s 236us/step - loss: 1.8862 - accuracy: 0.3154 - val_loss: 2.4487 - val_accuracy: 0.1610\n",
      "Epoch 49/450\n",
      "4896/4896 [==============================] - 1s 234us/step - loss: 1.9221 - accuracy: 0.2900 - val_loss: 2.3674 - val_accuracy: 0.1656\n",
      "Epoch 50/450\n",
      "4896/4896 [==============================] - 1s 237us/step - loss: 1.9078 - accuracy: 0.2994 - val_loss: 2.2384 - val_accuracy: 0.1733\n",
      "Epoch 51/450\n",
      "4896/4896 [==============================] - 1s 236us/step - loss: 1.8929 - accuracy: 0.3111 - val_loss: 2.3166 - val_accuracy: 0.1641\n",
      "Epoch 52/450\n",
      "4896/4896 [==============================] - 1s 235us/step - loss: 1.9044 - accuracy: 0.2990 - val_loss: 2.2264 - val_accuracy: 0.1518\n",
      "Epoch 53/450\n",
      "4896/4896 [==============================] - 1s 237us/step - loss: 1.9228 - accuracy: 0.2994 - val_loss: 2.3513 - val_accuracy: 0.1580\n",
      "Epoch 54/450\n",
      "4896/4896 [==============================] - 1s 238us/step - loss: 1.8963 - accuracy: 0.3002 - val_loss: 2.6818 - val_accuracy: 0.1242\n",
      "Epoch 55/450\n",
      "4896/4896 [==============================] - 1s 236us/step - loss: 1.9077 - accuracy: 0.3011 - val_loss: 2.3854 - val_accuracy: 0.1641\n",
      "Epoch 56/450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4896/4896 [==============================] - 1s 227us/step - loss: 1.8968 - accuracy: 0.3011 - val_loss: 2.3410 - val_accuracy: 0.1748\n",
      "Epoch 57/450\n",
      "4896/4896 [==============================] - 1s 227us/step - loss: 1.9078 - accuracy: 0.3137 - val_loss: 2.3098 - val_accuracy: 0.1656\n",
      "Epoch 58/450\n",
      "4896/4896 [==============================] - 1s 228us/step - loss: 1.9263 - accuracy: 0.2913 - val_loss: 2.3313 - val_accuracy: 0.1718\n",
      "Epoch 59/450\n",
      "4896/4896 [==============================] - 1s 241us/step - loss: 1.8919 - accuracy: 0.3066 - val_loss: 2.2333 - val_accuracy: 0.1687\n",
      "Epoch 60/450\n",
      "4896/4896 [==============================] - 1s 245us/step - loss: 1.8951 - accuracy: 0.3004 - val_loss: 2.2831 - val_accuracy: 0.1856\n",
      "Epoch 61/450\n",
      "4896/4896 [==============================] - 1s 250us/step - loss: 1.8929 - accuracy: 0.3033 - val_loss: 2.4388 - val_accuracy: 0.1610\n",
      "Epoch 62/450\n",
      "4896/4896 [==============================] - 1s 273us/step - loss: 1.9179 - accuracy: 0.2935 - val_loss: 2.4210 - val_accuracy: 0.1672\n",
      "Epoch 63/450\n",
      "4896/4896 [==============================] - 1s 254us/step - loss: 1.9132 - accuracy: 0.3043 - val_loss: 2.2004 - val_accuracy: 0.1871\n",
      "Epoch 64/450\n",
      "4896/4896 [==============================] - 1s 245us/step - loss: 1.8889 - accuracy: 0.3076 - val_loss: 2.3214 - val_accuracy: 0.1672\n",
      "Epoch 65/450\n",
      "4896/4896 [==============================] - 1s 239us/step - loss: 1.9176 - accuracy: 0.3023 - val_loss: 2.2762 - val_accuracy: 0.1810\n",
      "Epoch 66/450\n",
      "4896/4896 [==============================] - 1s 264us/step - loss: 1.9102 - accuracy: 0.2998 - val_loss: 2.2313 - val_accuracy: 0.1779\n",
      "Epoch 67/450\n",
      "4896/4896 [==============================] - 1s 212us/step - loss: 1.8933 - accuracy: 0.3064 - val_loss: 2.3978 - val_accuracy: 0.1503\n",
      "Epoch 68/450\n",
      "4896/4896 [==============================] - 1s 226us/step - loss: 1.8876 - accuracy: 0.3072 - val_loss: 2.2386 - val_accuracy: 0.1825\n",
      "Epoch 69/450\n",
      "4896/4896 [==============================] - 1s 239us/step - loss: 1.9084 - accuracy: 0.2900 - val_loss: 2.3266 - val_accuracy: 0.1641\n",
      "Epoch 70/450\n",
      "4896/4896 [==============================] - 1s 222us/step - loss: 1.8934 - accuracy: 0.3031 - val_loss: 2.2927 - val_accuracy: 0.1887\n",
      "Epoch 71/450\n",
      "4896/4896 [==============================] - 1s 245us/step - loss: 1.8917 - accuracy: 0.2998 - val_loss: 2.3121 - val_accuracy: 0.1810\n",
      "Epoch 72/450\n",
      "4896/4896 [==============================] - 1s 220us/step - loss: 1.8839 - accuracy: 0.3027 - val_loss: 2.1987 - val_accuracy: 0.1810\n",
      "Epoch 73/450\n",
      "4896/4896 [==============================] - 1s 215us/step - loss: 1.9122 - accuracy: 0.3017 - val_loss: 2.3062 - val_accuracy: 0.1733\n",
      "Epoch 74/450\n",
      "4896/4896 [==============================] - 1s 222us/step - loss: 1.8939 - accuracy: 0.2998 - val_loss: 2.3181 - val_accuracy: 0.1764\n",
      "Epoch 75/450\n",
      "4896/4896 [==============================] - 1s 255us/step - loss: 1.8871 - accuracy: 0.3041 - val_loss: 2.2697 - val_accuracy: 0.1856\n",
      "Epoch 76/450\n",
      "4896/4896 [==============================] - 1s 231us/step - loss: 1.9106 - accuracy: 0.2917 - val_loss: 2.2443 - val_accuracy: 0.1825\n",
      "Epoch 77/450\n",
      "4896/4896 [==============================] - 1s 260us/step - loss: 1.9026 - accuracy: 0.3035 - val_loss: 2.5443 - val_accuracy: 0.1549\n",
      "Epoch 78/450\n",
      "4896/4896 [==============================] - 1s 238us/step - loss: 1.9042 - accuracy: 0.3058 - val_loss: 2.2328 - val_accuracy: 0.1856\n",
      "Epoch 79/450\n",
      "4896/4896 [==============================] - 1s 247us/step - loss: 1.8961 - accuracy: 0.3023 - val_loss: 2.2290 - val_accuracy: 0.1887\n",
      "Epoch 80/450\n",
      "4896/4896 [==============================] - 1s 267us/step - loss: 1.9033 - accuracy: 0.2982 - val_loss: 2.2978 - val_accuracy: 0.1825\n",
      "Epoch 81/450\n",
      "4896/4896 [==============================] - 1s 238us/step - loss: 1.8837 - accuracy: 0.3117 - val_loss: 2.2870 - val_accuracy: 0.1948\n",
      "Epoch 82/450\n",
      "4896/4896 [==============================] - 1s 207us/step - loss: 1.8939 - accuracy: 0.2998 - val_loss: 2.2181 - val_accuracy: 0.1902\n",
      "Epoch 83/450\n",
      "4896/4896 [==============================] - 1s 235us/step - loss: 1.9031 - accuracy: 0.3021 - val_loss: 2.2440 - val_accuracy: 0.1672\n",
      "Epoch 84/450\n",
      "4896/4896 [==============================] - 1s 216us/step - loss: 1.8983 - accuracy: 0.3031 - val_loss: 2.2390 - val_accuracy: 0.1764\n",
      "Epoch 85/450\n",
      "4896/4896 [==============================] - 1s 239us/step - loss: 1.9037 - accuracy: 0.3009 - val_loss: 2.2025 - val_accuracy: 0.2071\n",
      "Epoch 86/450\n",
      "4896/4896 [==============================] - 1s 243us/step - loss: 1.8982 - accuracy: 0.3051 - val_loss: 2.2289 - val_accuracy: 0.1902\n",
      "Epoch 87/450\n",
      "4896/4896 [==============================] - 2s 329us/step - loss: 1.8966 - accuracy: 0.3064 - val_loss: 2.2519 - val_accuracy: 0.1656\n",
      "Epoch 88/450\n",
      "4896/4896 [==============================] - 1s 234us/step - loss: 1.8789 - accuracy: 0.3113 - val_loss: 2.4311 - val_accuracy: 0.1871\n",
      "Epoch 89/450\n",
      "4896/4896 [==============================] - 1s 218us/step - loss: 1.9068 - accuracy: 0.2986 - val_loss: 2.2573 - val_accuracy: 0.1871\n",
      "Epoch 90/450\n",
      "4896/4896 [==============================] - 1s 260us/step - loss: 1.8795 - accuracy: 0.3090 - val_loss: 2.2530 - val_accuracy: 0.1840\n",
      "Epoch 91/450\n",
      "4896/4896 [==============================] - 1s 219us/step - loss: 1.9010 - accuracy: 0.2984 - val_loss: 2.2043 - val_accuracy: 0.1825\n",
      "Epoch 92/450\n",
      "4896/4896 [==============================] - 1s 222us/step - loss: 1.8850 - accuracy: 0.3054 - val_loss: 2.4731 - val_accuracy: 0.1457\n",
      "Epoch 93/450\n",
      "4896/4896 [==============================] - 1s 218us/step - loss: 1.8910 - accuracy: 0.3039 - val_loss: 2.4913 - val_accuracy: 0.1626\n",
      "Epoch 94/450\n",
      "4896/4896 [==============================] - 1s 215us/step - loss: 1.8955 - accuracy: 0.3045 - val_loss: 2.2089 - val_accuracy: 0.1871\n",
      "Epoch 95/450\n",
      "4896/4896 [==============================] - 1s 228us/step - loss: 1.8787 - accuracy: 0.3033 - val_loss: 2.2605 - val_accuracy: 0.1672\n",
      "Epoch 96/450\n",
      "4896/4896 [==============================] - 1s 242us/step - loss: 1.8868 - accuracy: 0.3082 - val_loss: 2.5763 - val_accuracy: 0.1549\n",
      "Epoch 97/450\n",
      "4896/4896 [==============================] - 1s 247us/step - loss: 1.9083 - accuracy: 0.3027 - val_loss: 2.2153 - val_accuracy: 0.1887\n",
      "Epoch 98/450\n",
      "4896/4896 [==============================] - 1s 243us/step - loss: 1.8955 - accuracy: 0.3000 - val_loss: 2.1810 - val_accuracy: 0.1933\n",
      "Epoch 99/450\n",
      "4896/4896 [==============================] - 1s 270us/step - loss: 1.8796 - accuracy: 0.3107 - val_loss: 2.2765 - val_accuracy: 0.2009\n",
      "Epoch 100/450\n",
      "4896/4896 [==============================] - 1s 242us/step - loss: 1.8819 - accuracy: 0.3060 - val_loss: 2.2197 - val_accuracy: 0.1564\n",
      "Epoch 101/450\n",
      "4896/4896 [==============================] - 1s 240us/step - loss: 1.8960 - accuracy: 0.3150 - val_loss: 2.3121 - val_accuracy: 0.1917\n",
      "Epoch 102/450\n",
      "4896/4896 [==============================] - 1s 237us/step - loss: 1.8974 - accuracy: 0.3076 - val_loss: 2.1720 - val_accuracy: 0.1948\n",
      "Epoch 103/450\n",
      "4896/4896 [==============================] - 1s 217us/step - loss: 1.9021 - accuracy: 0.3062 - val_loss: 2.2829 - val_accuracy: 0.1963\n",
      "Epoch 104/450\n",
      "4896/4896 [==============================] - 1s 238us/step - loss: 1.8875 - accuracy: 0.3035 - val_loss: 2.4246 - val_accuracy: 0.1549\n",
      "Epoch 105/450\n",
      "4896/4896 [==============================] - 1s 221us/step - loss: 1.8920 - accuracy: 0.3041 - val_loss: 2.2956 - val_accuracy: 0.1764\n",
      "Epoch 106/450\n",
      "4896/4896 [==============================] - 1s 231us/step - loss: 1.8788 - accuracy: 0.3109 - val_loss: 2.4628 - val_accuracy: 0.1610\n",
      "Epoch 107/450\n",
      "4896/4896 [==============================] - 1s 208us/step - loss: 1.8980 - accuracy: 0.3041 - val_loss: 2.4554 - val_accuracy: 0.1534\n",
      "Epoch 108/450\n",
      "4896/4896 [==============================] - 1s 211us/step - loss: 1.8872 - accuracy: 0.3004 - val_loss: 2.2770 - val_accuracy: 0.1856\n",
      "Epoch 109/450\n",
      "4896/4896 [==============================] - 1s 224us/step - loss: 1.8849 - accuracy: 0.3047 - val_loss: 2.4783 - val_accuracy: 0.1610\n",
      "Epoch 110/450\n",
      "4896/4896 [==============================] - 1s 211us/step - loss: 1.8969 - accuracy: 0.3017 - val_loss: 2.3654 - val_accuracy: 0.1702\n",
      "Epoch 111/450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4896/4896 [==============================] - 1s 212us/step - loss: 1.8788 - accuracy: 0.3096 - val_loss: 2.3239 - val_accuracy: 0.1672\n",
      "Epoch 112/450\n",
      "4896/4896 [==============================] - 1s 207us/step - loss: 1.8761 - accuracy: 0.3062 - val_loss: 2.4267 - val_accuracy: 0.1442\n",
      "Epoch 113/450\n",
      "4896/4896 [==============================] - 1s 210us/step - loss: 1.8748 - accuracy: 0.3180 - val_loss: 2.5415 - val_accuracy: 0.1641\n",
      "Epoch 114/450\n",
      "4896/4896 [==============================] - 1s 212us/step - loss: 1.8857 - accuracy: 0.2990 - val_loss: 2.2223 - val_accuracy: 0.1963\n",
      "Epoch 115/450\n",
      "4896/4896 [==============================] - 1s 214us/step - loss: 1.8840 - accuracy: 0.3092 - val_loss: 2.2888 - val_accuracy: 0.1840\n",
      "Epoch 116/450\n",
      "4896/4896 [==============================] - 1s 209us/step - loss: 1.8743 - accuracy: 0.3092 - val_loss: 2.3443 - val_accuracy: 0.1580\n",
      "Epoch 117/450\n",
      "4896/4896 [==============================] - 1s 212us/step - loss: 1.8732 - accuracy: 0.3076 - val_loss: 2.2253 - val_accuracy: 0.1825\n",
      "Epoch 118/450\n",
      "4896/4896 [==============================] - 1s 213us/step - loss: 1.8779 - accuracy: 0.3068 - val_loss: 2.2175 - val_accuracy: 0.1994\n",
      "Epoch 119/450\n",
      "4896/4896 [==============================] - 1s 214us/step - loss: 1.8698 - accuracy: 0.3154 - val_loss: 2.3251 - val_accuracy: 0.1656\n",
      "Epoch 120/450\n",
      "4896/4896 [==============================] - 1s 236us/step - loss: 1.8861 - accuracy: 0.3041 - val_loss: 2.1803 - val_accuracy: 0.2009\n",
      "Epoch 121/450\n",
      "4896/4896 [==============================] - 1s 214us/step - loss: 1.8869 - accuracy: 0.3007 - val_loss: 2.3135 - val_accuracy: 0.1702\n",
      "Epoch 122/450\n",
      "4896/4896 [==============================] - 1s 217us/step - loss: 1.8700 - accuracy: 0.3047 - val_loss: 2.3484 - val_accuracy: 0.1963\n",
      "Epoch 123/450\n",
      "4896/4896 [==============================] - 1s 216us/step - loss: 1.8942 - accuracy: 0.2960 - val_loss: 2.3182 - val_accuracy: 0.1672\n",
      "Epoch 124/450\n",
      "4896/4896 [==============================] - 1s 229us/step - loss: 1.8685 - accuracy: 0.3176 - val_loss: 2.4280 - val_accuracy: 0.1825\n",
      "Epoch 125/450\n",
      "4896/4896 [==============================] - 1s 221us/step - loss: 1.8805 - accuracy: 0.3064 - val_loss: 2.3018 - val_accuracy: 0.1564\n",
      "Epoch 126/450\n",
      "4896/4896 [==============================] - 1s 206us/step - loss: 1.8805 - accuracy: 0.3054 - val_loss: 2.2026 - val_accuracy: 0.1825\n",
      "Epoch 127/450\n",
      "4896/4896 [==============================] - 1s 226us/step - loss: 1.8809 - accuracy: 0.3062 - val_loss: 2.3714 - val_accuracy: 0.1933\n",
      "Epoch 128/450\n",
      "4896/4896 [==============================] - 1s 225us/step - loss: 1.8747 - accuracy: 0.3080 - val_loss: 2.4318 - val_accuracy: 0.1380\n",
      "Epoch 129/450\n",
      "4896/4896 [==============================] - 1s 227us/step - loss: 1.8720 - accuracy: 0.3141 - val_loss: 2.4863 - val_accuracy: 0.1748\n",
      "Epoch 130/450\n",
      "4896/4896 [==============================] - 1s 217us/step - loss: 1.8917 - accuracy: 0.3098 - val_loss: 2.2385 - val_accuracy: 0.1840\n",
      "Epoch 131/450\n",
      "4896/4896 [==============================] - 1s 227us/step - loss: 1.8662 - accuracy: 0.3184 - val_loss: 2.4177 - val_accuracy: 0.1718\n",
      "Epoch 132/450\n",
      "4896/4896 [==============================] - 1s 229us/step - loss: 1.8792 - accuracy: 0.3074 - val_loss: 2.2342 - val_accuracy: 0.1887\n",
      "Epoch 133/450\n",
      "4896/4896 [==============================] - 1s 262us/step - loss: 1.8894 - accuracy: 0.2982 - val_loss: 2.3031 - val_accuracy: 0.1687\n",
      "Epoch 134/450\n",
      "4896/4896 [==============================] - 1s 220us/step - loss: 1.8676 - accuracy: 0.3156 - val_loss: 2.2253 - val_accuracy: 0.1733\n",
      "Epoch 135/450\n",
      "4896/4896 [==============================] - 1s 258us/step - loss: 1.8744 - accuracy: 0.3072 - val_loss: 2.2541 - val_accuracy: 0.1764\n",
      "Epoch 136/450\n",
      "4896/4896 [==============================] - 1s 305us/step - loss: 1.8780 - accuracy: 0.3109 - val_loss: 2.2181 - val_accuracy: 0.2071\n",
      "Epoch 137/450\n",
      "4896/4896 [==============================] - 2s 396us/step - loss: 1.8702 - accuracy: 0.3051 - val_loss: 2.3269 - val_accuracy: 0.1641\n",
      "Epoch 138/450\n",
      "4896/4896 [==============================] - 2s 395us/step - loss: 1.8923 - accuracy: 0.3035 - val_loss: 2.2727 - val_accuracy: 0.1825\n",
      "Epoch 139/450\n",
      "4896/4896 [==============================] - 2s 335us/step - loss: 1.8754 - accuracy: 0.3109 - val_loss: 2.6223 - val_accuracy: 0.1626\n",
      "Epoch 140/450\n",
      "4896/4896 [==============================] - 1s 224us/step - loss: 1.9072 - accuracy: 0.3082 - val_loss: 2.2212 - val_accuracy: 0.2040\n",
      "Epoch 141/450\n",
      "4896/4896 [==============================] - 1s 205us/step - loss: 1.8680 - accuracy: 0.3137 - val_loss: 2.2736 - val_accuracy: 0.1917\n",
      "Epoch 142/450\n",
      "4896/4896 [==============================] - 1s 229us/step - loss: 1.8655 - accuracy: 0.3125 - val_loss: 2.3430 - val_accuracy: 0.1641\n",
      "Epoch 143/450\n",
      "4896/4896 [==============================] - 1s 236us/step - loss: 1.8731 - accuracy: 0.3107 - val_loss: 2.2394 - val_accuracy: 0.1933\n",
      "Epoch 144/450\n",
      "4896/4896 [==============================] - 1s 214us/step - loss: 1.8735 - accuracy: 0.3107 - val_loss: 2.2237 - val_accuracy: 0.2040\n",
      "Epoch 145/450\n",
      "4896/4896 [==============================] - 1s 239us/step - loss: 1.8662 - accuracy: 0.3098 - val_loss: 2.3809 - val_accuracy: 0.1963\n",
      "Epoch 146/450\n",
      "4896/4896 [==============================] - 1s 220us/step - loss: 1.8676 - accuracy: 0.3125 - val_loss: 2.2846 - val_accuracy: 0.1810\n",
      "Epoch 147/450\n",
      "4896/4896 [==============================] - 1s 230us/step - loss: 1.8784 - accuracy: 0.3037 - val_loss: 2.3539 - val_accuracy: 0.1534\n",
      "Epoch 148/450\n",
      "4896/4896 [==============================] - 1s 224us/step - loss: 1.8820 - accuracy: 0.3115 - val_loss: 2.3944 - val_accuracy: 0.1917\n",
      "Epoch 149/450\n",
      "4896/4896 [==============================] - 1s 238us/step - loss: 1.8522 - accuracy: 0.3182 - val_loss: 2.2167 - val_accuracy: 0.1687\n",
      "Epoch 150/450\n",
      "4896/4896 [==============================] - 1s 214us/step - loss: 1.8731 - accuracy: 0.3141 - val_loss: 2.1945 - val_accuracy: 0.1779\n",
      "Epoch 151/450\n",
      "4896/4896 [==============================] - 1s 217us/step - loss: 1.8686 - accuracy: 0.3082 - val_loss: 2.1972 - val_accuracy: 0.2071\n",
      "Epoch 152/450\n",
      "4896/4896 [==============================] - 1s 224us/step - loss: 1.8630 - accuracy: 0.3143 - val_loss: 2.3054 - val_accuracy: 0.1733\n",
      "Epoch 153/450\n",
      "4896/4896 [==============================] - 1s 222us/step - loss: 1.8940 - accuracy: 0.3064 - val_loss: 2.2089 - val_accuracy: 0.2132\n",
      "Epoch 154/450\n",
      "4896/4896 [==============================] - 1s 211us/step - loss: 1.8733 - accuracy: 0.3025 - val_loss: 2.3569 - val_accuracy: 0.1718\n",
      "Epoch 155/450\n",
      "4896/4896 [==============================] - 1s 217us/step - loss: 1.8583 - accuracy: 0.3143 - val_loss: 2.2980 - val_accuracy: 0.1779\n",
      "Epoch 156/450\n",
      "4896/4896 [==============================] - 1s 223us/step - loss: 1.8703 - accuracy: 0.3082 - val_loss: 2.1968 - val_accuracy: 0.1902\n",
      "Epoch 157/450\n",
      "4896/4896 [==============================] - 1s 228us/step - loss: 1.8583 - accuracy: 0.3123 - val_loss: 2.2079 - val_accuracy: 0.1933\n",
      "Epoch 158/450\n",
      "4896/4896 [==============================] - 1s 220us/step - loss: 1.8638 - accuracy: 0.3176 - val_loss: 2.2539 - val_accuracy: 0.1840\n",
      "Epoch 159/450\n",
      "4896/4896 [==============================] - 1s 219us/step - loss: 1.8759 - accuracy: 0.3162 - val_loss: 2.2672 - val_accuracy: 0.1580\n",
      "Epoch 160/450\n",
      "4896/4896 [==============================] - 1s 215us/step - loss: 1.8596 - accuracy: 0.3164 - val_loss: 2.3960 - val_accuracy: 0.1794\n",
      "Epoch 161/450\n",
      "4896/4896 [==============================] - 1s 215us/step - loss: 1.8636 - accuracy: 0.3143 - val_loss: 2.5218 - val_accuracy: 0.1626\n",
      "Epoch 162/450\n",
      "4896/4896 [==============================] - 1s 212us/step - loss: 1.8666 - accuracy: 0.3068 - val_loss: 2.2939 - val_accuracy: 0.1917\n",
      "Epoch 163/450\n",
      "4896/4896 [==============================] - 1s 215us/step - loss: 1.8566 - accuracy: 0.3162 - val_loss: 2.6834 - val_accuracy: 0.1626\n",
      "Epoch 164/450\n",
      "4896/4896 [==============================] - 1s 220us/step - loss: 1.8651 - accuracy: 0.3123 - val_loss: 2.3327 - val_accuracy: 0.1733\n",
      "Epoch 165/450\n",
      "4896/4896 [==============================] - 1s 236us/step - loss: 1.8565 - accuracy: 0.3168 - val_loss: 2.3893 - val_accuracy: 0.1902\n",
      "Epoch 166/450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4896/4896 [==============================] - 1s 224us/step - loss: 1.8623 - accuracy: 0.3170 - val_loss: 2.1919 - val_accuracy: 0.2009\n",
      "Epoch 167/450\n",
      "4896/4896 [==============================] - 1s 218us/step - loss: 1.8624 - accuracy: 0.3105 - val_loss: 2.2038 - val_accuracy: 0.1825\n",
      "Epoch 168/450\n",
      "4896/4896 [==============================] - 1s 218us/step - loss: 1.8752 - accuracy: 0.3115 - val_loss: 2.2609 - val_accuracy: 0.1871\n",
      "Epoch 169/450\n",
      "4896/4896 [==============================] - 1s 218us/step - loss: 1.8575 - accuracy: 0.3231 - val_loss: 2.4020 - val_accuracy: 0.1564\n",
      "Epoch 170/450\n",
      "4896/4896 [==============================] - 1s 214us/step - loss: 1.8862 - accuracy: 0.3141 - val_loss: 2.3141 - val_accuracy: 0.1672\n",
      "Epoch 171/450\n",
      "4896/4896 [==============================] - 1s 218us/step - loss: 1.8626 - accuracy: 0.3192 - val_loss: 2.4028 - val_accuracy: 0.1626\n",
      "Epoch 172/450\n",
      "4896/4896 [==============================] - 1s 225us/step - loss: 1.8694 - accuracy: 0.3105 - val_loss: 2.1923 - val_accuracy: 0.1948\n",
      "Epoch 173/450\n",
      "4896/4896 [==============================] - 1s 217us/step - loss: 1.8605 - accuracy: 0.3180 - val_loss: 2.4857 - val_accuracy: 0.1472\n",
      "Epoch 174/450\n",
      "4896/4896 [==============================] - 1s 216us/step - loss: 1.8525 - accuracy: 0.3109 - val_loss: 2.3470 - val_accuracy: 0.1610\n",
      "Epoch 175/450\n",
      "4896/4896 [==============================] - 1s 212us/step - loss: 1.8486 - accuracy: 0.3172 - val_loss: 2.2004 - val_accuracy: 0.1856\n",
      "Epoch 176/450\n",
      "4896/4896 [==============================] - 1s 241us/step - loss: 1.8775 - accuracy: 0.2996 - val_loss: 2.2167 - val_accuracy: 0.2009\n",
      "Epoch 177/450\n",
      "4896/4896 [==============================] - 2s 322us/step - loss: 1.8564 - accuracy: 0.3150 - val_loss: 2.4161 - val_accuracy: 0.1794\n",
      "Epoch 178/450\n",
      "4896/4896 [==============================] - 2s 371us/step - loss: 1.8633 - accuracy: 0.3133 - val_loss: 2.2266 - val_accuracy: 0.2117\n",
      "Epoch 179/450\n",
      "4896/4896 [==============================] - 2s 314us/step - loss: 1.8659 - accuracy: 0.3178 - val_loss: 2.3471 - val_accuracy: 0.1718\n",
      "Epoch 180/450\n",
      "4896/4896 [==============================] - 1s 259us/step - loss: 1.8648 - accuracy: 0.3168 - val_loss: 2.3703 - val_accuracy: 0.1518\n",
      "Epoch 181/450\n",
      "4896/4896 [==============================] - 1s 245us/step - loss: 1.8421 - accuracy: 0.3194 - val_loss: 2.2524 - val_accuracy: 0.1840\n",
      "Epoch 182/450\n",
      "4896/4896 [==============================] - 1s 207us/step - loss: 1.8493 - accuracy: 0.3152 - val_loss: 2.3095 - val_accuracy: 0.1902\n",
      "Epoch 183/450\n",
      "4896/4896 [==============================] - 1s 226us/step - loss: 1.8714 - accuracy: 0.3007 - val_loss: 2.2599 - val_accuracy: 0.1764\n",
      "Epoch 184/450\n",
      "4896/4896 [==============================] - 1s 249us/step - loss: 1.8444 - accuracy: 0.3248 - val_loss: 2.3428 - val_accuracy: 0.1871\n",
      "Epoch 185/450\n",
      "4896/4896 [==============================] - 1s 295us/step - loss: 1.8560 - accuracy: 0.3164 - val_loss: 2.4936 - val_accuracy: 0.1764\n",
      "Epoch 186/450\n",
      "4896/4896 [==============================] - 2s 476us/step - loss: 1.8551 - accuracy: 0.3176 - val_loss: 2.2455 - val_accuracy: 0.1933\n",
      "Epoch 187/450\n",
      "4896/4896 [==============================] - 2s 501us/step - loss: 1.8759 - accuracy: 0.3111 - val_loss: 2.2724 - val_accuracy: 0.1871\n",
      "Epoch 188/450\n",
      "4896/4896 [==============================] - 2s 374us/step - loss: 1.8587 - accuracy: 0.3164 - val_loss: 2.4424 - val_accuracy: 0.1733\n",
      "Epoch 189/450\n",
      "4896/4896 [==============================] - 2s 409us/step - loss: 1.8427 - accuracy: 0.3186 - val_loss: 2.1855 - val_accuracy: 0.2025\n",
      "Epoch 190/450\n",
      "4896/4896 [==============================] - 1s 299us/step - loss: 1.8650 - accuracy: 0.3135 - val_loss: 2.2287 - val_accuracy: 0.2071\n",
      "Epoch 191/450\n",
      "4896/4896 [==============================] - 1s 299us/step - loss: 1.8424 - accuracy: 0.3137 - val_loss: 2.4203 - val_accuracy: 0.1411\n",
      "Epoch 192/450\n",
      "4896/4896 [==============================] - 2s 332us/step - loss: 1.8577 - accuracy: 0.3100 - val_loss: 2.2500 - val_accuracy: 0.1917\n",
      "Epoch 193/450\n",
      "4896/4896 [==============================] - 1s 249us/step - loss: 1.8519 - accuracy: 0.3172 - val_loss: 2.2537 - val_accuracy: 0.2101\n",
      "Epoch 194/450\n",
      "4896/4896 [==============================] - 1s 248us/step - loss: 1.8590 - accuracy: 0.3158 - val_loss: 2.2579 - val_accuracy: 0.1871\n",
      "Epoch 195/450\n",
      "4896/4896 [==============================] - 1s 251us/step - loss: 1.8425 - accuracy: 0.3235 - val_loss: 2.3977 - val_accuracy: 0.1794\n",
      "Epoch 196/450\n",
      "4896/4896 [==============================] - 1s 253us/step - loss: 1.8619 - accuracy: 0.3062 - val_loss: 2.2027 - val_accuracy: 0.1994\n",
      "Epoch 197/450\n",
      "4896/4896 [==============================] - 1s 258us/step - loss: 1.8480 - accuracy: 0.3246 - val_loss: 2.2252 - val_accuracy: 0.1764\n",
      "Epoch 198/450\n",
      "4896/4896 [==============================] - 1s 239us/step - loss: 1.8395 - accuracy: 0.3170 - val_loss: 2.2545 - val_accuracy: 0.1794\n",
      "Epoch 199/450\n",
      "4896/4896 [==============================] - 1s 270us/step - loss: 1.8748 - accuracy: 0.3129 - val_loss: 2.2289 - val_accuracy: 0.2086\n",
      "Epoch 200/450\n",
      "4896/4896 [==============================] - 1s 244us/step - loss: 1.8423 - accuracy: 0.3209 - val_loss: 2.2374 - val_accuracy: 0.1917\n",
      "Epoch 201/450\n",
      "4896/4896 [==============================] - 1s 239us/step - loss: 1.8590 - accuracy: 0.3164 - val_loss: 2.2896 - val_accuracy: 0.1963\n",
      "Epoch 202/450\n",
      "4896/4896 [==============================] - 1s 256us/step - loss: 1.8448 - accuracy: 0.3145 - val_loss: 2.1910 - val_accuracy: 0.1948\n",
      "Epoch 203/450\n",
      "4896/4896 [==============================] - 1s 286us/step - loss: 1.8701 - accuracy: 0.3166 - val_loss: 2.2349 - val_accuracy: 0.1933\n",
      "Epoch 204/450\n",
      "4896/4896 [==============================] - 1s 248us/step - loss: 1.8668 - accuracy: 0.3207 - val_loss: 2.2143 - val_accuracy: 0.1856\n",
      "Epoch 205/450\n",
      "4896/4896 [==============================] - 1s 245us/step - loss: 1.8347 - accuracy: 0.3248 - val_loss: 2.3264 - val_accuracy: 0.1979\n",
      "Epoch 206/450\n",
      "4896/4896 [==============================] - 1s 262us/step - loss: 1.8517 - accuracy: 0.3125 - val_loss: 2.2647 - val_accuracy: 0.1779\n",
      "Epoch 207/450\n",
      "4896/4896 [==============================] - 1s 242us/step - loss: 1.8497 - accuracy: 0.3196 - val_loss: 2.5786 - val_accuracy: 0.1641\n",
      "Epoch 208/450\n",
      "4896/4896 [==============================] - 1s 240us/step - loss: 1.8527 - accuracy: 0.3207 - val_loss: 2.3230 - val_accuracy: 0.1810\n",
      "Epoch 209/450\n",
      "4896/4896 [==============================] - 1s 226us/step - loss: 1.8508 - accuracy: 0.3188 - val_loss: 2.2287 - val_accuracy: 0.1856\n",
      "Epoch 210/450\n",
      "4896/4896 [==============================] - 1s 237us/step - loss: 1.8422 - accuracy: 0.3201 - val_loss: 2.2006 - val_accuracy: 0.1871\n",
      "Epoch 211/450\n",
      "4896/4896 [==============================] - 1s 235us/step - loss: 1.8393 - accuracy: 0.3327 - val_loss: 2.3829 - val_accuracy: 0.1672\n",
      "Epoch 212/450\n",
      "4896/4896 [==============================] - 1s 239us/step - loss: 1.8411 - accuracy: 0.3237 - val_loss: 2.3157 - val_accuracy: 0.2055\n",
      "Epoch 213/450\n",
      "4896/4896 [==============================] - 1s 237us/step - loss: 1.8399 - accuracy: 0.3192 - val_loss: 2.1910 - val_accuracy: 0.1748\n",
      "Epoch 214/450\n",
      "4896/4896 [==============================] - 1s 222us/step - loss: 1.8505 - accuracy: 0.3178 - val_loss: 2.3192 - val_accuracy: 0.1733\n",
      "Epoch 215/450\n",
      "4896/4896 [==============================] - 1s 226us/step - loss: 1.8412 - accuracy: 0.3235 - val_loss: 2.2429 - val_accuracy: 0.1825\n",
      "Epoch 216/450\n",
      "4896/4896 [==============================] - 1s 239us/step - loss: 1.8486 - accuracy: 0.3158 - val_loss: 2.3324 - val_accuracy: 0.1672\n",
      "Epoch 217/450\n",
      "4896/4896 [==============================] - 1s 244us/step - loss: 1.8605 - accuracy: 0.3131 - val_loss: 2.2955 - val_accuracy: 0.2101\n",
      "Epoch 218/450\n",
      "4896/4896 [==============================] - 1s 238us/step - loss: 1.8323 - accuracy: 0.3160 - val_loss: 2.2640 - val_accuracy: 0.1748\n",
      "Epoch 219/450\n",
      "4896/4896 [==============================] - 1s 238us/step - loss: 1.8585 - accuracy: 0.3156 - val_loss: 2.2569 - val_accuracy: 0.1794\n",
      "Epoch 220/450\n",
      "4896/4896 [==============================] - 1s 291us/step - loss: 1.8472 - accuracy: 0.3172 - val_loss: 2.1936 - val_accuracy: 0.2285\n",
      "Epoch 221/450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4896/4896 [==============================] - 2s 323us/step - loss: 1.8358 - accuracy: 0.3205 - val_loss: 2.2186 - val_accuracy: 0.1856\n",
      "Epoch 222/450\n",
      "4896/4896 [==============================] - 1s 250us/step - loss: 1.8460 - accuracy: 0.3227 - val_loss: 2.3247 - val_accuracy: 0.1764\n",
      "Epoch 223/450\n",
      "4896/4896 [==============================] - 1s 216us/step - loss: 1.8455 - accuracy: 0.3143 - val_loss: 2.2160 - val_accuracy: 0.1764\n",
      "Epoch 224/450\n",
      "4896/4896 [==============================] - 1s 217us/step - loss: 1.8387 - accuracy: 0.3172 - val_loss: 2.1666 - val_accuracy: 0.2071\n",
      "Epoch 225/450\n",
      "4896/4896 [==============================] - 1s 211us/step - loss: 1.8363 - accuracy: 0.3145 - val_loss: 2.2114 - val_accuracy: 0.1994\n",
      "Epoch 226/450\n",
      "4896/4896 [==============================] - 1s 220us/step - loss: 1.8458 - accuracy: 0.3117 - val_loss: 2.3311 - val_accuracy: 0.1994\n",
      "Epoch 227/450\n",
      "4896/4896 [==============================] - 1s 213us/step - loss: 1.8382 - accuracy: 0.3174 - val_loss: 2.2562 - val_accuracy: 0.1779\n",
      "Epoch 228/450\n",
      "4896/4896 [==============================] - 1s 215us/step - loss: 1.8653 - accuracy: 0.3137 - val_loss: 2.2456 - val_accuracy: 0.2071\n",
      "Epoch 229/450\n",
      "4896/4896 [==============================] - 1s 223us/step - loss: 1.8333 - accuracy: 0.3297 - val_loss: 2.2253 - val_accuracy: 0.1825\n",
      "Epoch 230/450\n",
      "4896/4896 [==============================] - 1s 214us/step - loss: 1.8416 - accuracy: 0.3241 - val_loss: 2.3683 - val_accuracy: 0.1902\n",
      "Epoch 231/450\n",
      "4896/4896 [==============================] - 1s 217us/step - loss: 1.8495 - accuracy: 0.3178 - val_loss: 2.2277 - val_accuracy: 0.1733\n",
      "Epoch 232/450\n",
      "4896/4896 [==============================] - 1s 211us/step - loss: 1.8449 - accuracy: 0.3182 - val_loss: 2.2142 - val_accuracy: 0.1948\n",
      "Epoch 233/450\n",
      "4896/4896 [==============================] - 1s 245us/step - loss: 1.8187 - accuracy: 0.3292 - val_loss: 2.3854 - val_accuracy: 0.1810\n",
      "Epoch 234/450\n",
      "4896/4896 [==============================] - 1s 234us/step - loss: 1.8533 - accuracy: 0.3156 - val_loss: 2.2796 - val_accuracy: 0.1856\n",
      "Epoch 235/450\n",
      "4896/4896 [==============================] - 1s 222us/step - loss: 1.8441 - accuracy: 0.3237 - val_loss: 2.2248 - val_accuracy: 0.1733\n",
      "Epoch 236/450\n",
      "4896/4896 [==============================] - 1s 225us/step - loss: 1.8390 - accuracy: 0.3199 - val_loss: 2.2485 - val_accuracy: 0.1963\n",
      "Epoch 237/450\n",
      "4896/4896 [==============================] - 1s 219us/step - loss: 1.8476 - accuracy: 0.3246 - val_loss: 2.2385 - val_accuracy: 0.1917\n",
      "Epoch 238/450\n",
      "4896/4896 [==============================] - 1s 233us/step - loss: 1.8143 - accuracy: 0.3288 - val_loss: 2.5708 - val_accuracy: 0.1426\n",
      "Epoch 239/450\n",
      "4896/4896 [==============================] - 1s 220us/step - loss: 1.8471 - accuracy: 0.3168 - val_loss: 2.2409 - val_accuracy: 0.1764\n",
      "Epoch 240/450\n",
      "4896/4896 [==============================] - 1s 247us/step - loss: 1.8449 - accuracy: 0.3152 - val_loss: 2.2747 - val_accuracy: 0.2117\n",
      "Epoch 241/450\n",
      "4896/4896 [==============================] - 1s 271us/step - loss: 1.8338 - accuracy: 0.3170 - val_loss: 2.5963 - val_accuracy: 0.1672\n",
      "Epoch 242/450\n",
      "4896/4896 [==============================] - 1s 287us/step - loss: 1.8313 - accuracy: 0.3209 - val_loss: 2.2066 - val_accuracy: 0.2025\n",
      "Epoch 243/450\n",
      "4896/4896 [==============================] - 1s 237us/step - loss: 1.8307 - accuracy: 0.3176 - val_loss: 2.2254 - val_accuracy: 0.1794\n",
      "Epoch 244/450\n",
      "4896/4896 [==============================] - 1s 218us/step - loss: 1.8449 - accuracy: 0.3109 - val_loss: 2.2261 - val_accuracy: 0.1887\n",
      "Epoch 245/450\n",
      "4896/4896 [==============================] - 1s 218us/step - loss: 1.8292 - accuracy: 0.3237 - val_loss: 2.2524 - val_accuracy: 0.1810\n",
      "Epoch 246/450\n",
      "4896/4896 [==============================] - 1s 226us/step - loss: 1.8380 - accuracy: 0.3172 - val_loss: 2.2763 - val_accuracy: 0.1979\n",
      "Epoch 247/450\n",
      "4896/4896 [==============================] - 1s 228us/step - loss: 1.8275 - accuracy: 0.3290 - val_loss: 2.2440 - val_accuracy: 0.1917\n",
      "Epoch 248/450\n",
      "4896/4896 [==============================] - 1s 217us/step - loss: 1.8359 - accuracy: 0.3174 - val_loss: 2.2409 - val_accuracy: 0.1902\n",
      "Epoch 249/450\n",
      "4896/4896 [==============================] - 1s 215us/step - loss: 1.8333 - accuracy: 0.3254 - val_loss: 2.2225 - val_accuracy: 0.1902\n",
      "Epoch 250/450\n",
      "4896/4896 [==============================] - 1s 225us/step - loss: 1.8230 - accuracy: 0.3241 - val_loss: 2.5874 - val_accuracy: 0.1825\n",
      "Epoch 251/450\n",
      "4896/4896 [==============================] - 1s 277us/step - loss: 1.8744 - accuracy: 0.3170 - val_loss: 2.4436 - val_accuracy: 0.1656\n",
      "Epoch 252/450\n",
      "4896/4896 [==============================] - 1s 223us/step - loss: 1.8248 - accuracy: 0.3274 - val_loss: 2.2650 - val_accuracy: 0.1887\n",
      "Epoch 253/450\n",
      "4896/4896 [==============================] - 1s 225us/step - loss: 1.8234 - accuracy: 0.3258 - val_loss: 2.3200 - val_accuracy: 0.2040\n",
      "Epoch 254/450\n",
      "4896/4896 [==============================] - 1s 222us/step - loss: 1.8434 - accuracy: 0.3229 - val_loss: 2.2341 - val_accuracy: 0.1994\n",
      "Epoch 255/450\n",
      "4896/4896 [==============================] - 1s 247us/step - loss: 1.8269 - accuracy: 0.3278 - val_loss: 2.5148 - val_accuracy: 0.1595\n",
      "Epoch 256/450\n",
      "4896/4896 [==============================] - 1s 240us/step - loss: 1.8375 - accuracy: 0.3233 - val_loss: 3.5276 - val_accuracy: 0.1748\n",
      "Epoch 257/450\n",
      "4896/4896 [==============================] - 1s 225us/step - loss: 1.8818 - accuracy: 0.3098 - val_loss: 2.2166 - val_accuracy: 0.2086\n",
      "Epoch 258/450\n",
      "4896/4896 [==============================] - 1s 246us/step - loss: 1.8351 - accuracy: 0.3196 - val_loss: 2.2441 - val_accuracy: 0.1871\n",
      "Epoch 259/450\n",
      "4896/4896 [==============================] - 1s 247us/step - loss: 1.8332 - accuracy: 0.3203 - val_loss: 2.3291 - val_accuracy: 0.2055\n",
      "Epoch 260/450\n",
      "4896/4896 [==============================] - 1s 233us/step - loss: 1.8379 - accuracy: 0.3192 - val_loss: 2.3188 - val_accuracy: 0.1794\n",
      "Epoch 261/450\n",
      "4896/4896 [==============================] - 1s 227us/step - loss: 1.8328 - accuracy: 0.3174 - val_loss: 2.2716 - val_accuracy: 0.1718\n",
      "Epoch 262/450\n",
      "4896/4896 [==============================] - 1s 221us/step - loss: 1.8326 - accuracy: 0.3246 - val_loss: 2.2339 - val_accuracy: 0.1963\n",
      "Epoch 263/450\n",
      "4896/4896 [==============================] - 1s 238us/step - loss: 1.8289 - accuracy: 0.3258 - val_loss: 2.3951 - val_accuracy: 0.1748\n",
      "Epoch 264/450\n",
      "4896/4896 [==============================] - 1s 295us/step - loss: 1.8260 - accuracy: 0.3152 - val_loss: 2.2116 - val_accuracy: 0.2117\n",
      "Epoch 265/450\n",
      "4896/4896 [==============================] - 1s 244us/step - loss: 1.8245 - accuracy: 0.3235 - val_loss: 2.4189 - val_accuracy: 0.1488\n",
      "Epoch 266/450\n",
      "4896/4896 [==============================] - 1s 227us/step - loss: 1.8370 - accuracy: 0.3184 - val_loss: 2.2431 - val_accuracy: 0.1856\n",
      "Epoch 267/450\n",
      "4896/4896 [==============================] - 1s 240us/step - loss: 1.8331 - accuracy: 0.3211 - val_loss: 2.2213 - val_accuracy: 0.1933\n",
      "Epoch 268/450\n",
      "4896/4896 [==============================] - 1s 206us/step - loss: 1.8185 - accuracy: 0.3282 - val_loss: 2.5927 - val_accuracy: 0.1779\n",
      "Epoch 269/450\n",
      "4896/4896 [==============================] - 1s 253us/step - loss: 1.8426 - accuracy: 0.3262 - val_loss: 2.2447 - val_accuracy: 0.1887\n",
      "Epoch 270/450\n",
      "4896/4896 [==============================] - 1s 240us/step - loss: 1.8272 - accuracy: 0.3266 - val_loss: 2.2795 - val_accuracy: 0.1748\n",
      "Epoch 271/450\n",
      "4896/4896 [==============================] - 1s 240us/step - loss: 1.8199 - accuracy: 0.3264 - val_loss: 2.2213 - val_accuracy: 0.1963\n",
      "Epoch 272/450\n",
      "4896/4896 [==============================] - 1s 240us/step - loss: 1.8198 - accuracy: 0.3315 - val_loss: 2.8278 - val_accuracy: 0.1488\n",
      "Epoch 273/450\n",
      "4896/4896 [==============================] - 1s 247us/step - loss: 1.8368 - accuracy: 0.3207 - val_loss: 2.1974 - val_accuracy: 0.2117\n",
      "Epoch 274/450\n",
      "4896/4896 [==============================] - 1s 219us/step - loss: 1.8331 - accuracy: 0.3162 - val_loss: 2.2092 - val_accuracy: 0.1948\n",
      "Epoch 275/450\n",
      "4896/4896 [==============================] - 1s 219us/step - loss: 1.8079 - accuracy: 0.3342 - val_loss: 2.1902 - val_accuracy: 0.1887\n",
      "Epoch 276/450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4896/4896 [==============================] - 1s 214us/step - loss: 1.8867 - accuracy: 0.3235 - val_loss: 2.2033 - val_accuracy: 0.1871\n",
      "Epoch 277/450\n",
      "4896/4896 [==============================] - 1s 222us/step - loss: 1.8305 - accuracy: 0.3207 - val_loss: 2.3313 - val_accuracy: 0.1856\n",
      "Epoch 278/450\n",
      "4896/4896 [==============================] - 1s 248us/step - loss: 1.8076 - accuracy: 0.3378 - val_loss: 2.1842 - val_accuracy: 0.1794\n",
      "Epoch 279/450\n",
      "4896/4896 [==============================] - 1s 246us/step - loss: 1.8452 - accuracy: 0.3182 - val_loss: 2.3079 - val_accuracy: 0.1871\n",
      "Epoch 280/450\n",
      "4896/4896 [==============================] - 1s 215us/step - loss: 1.8262 - accuracy: 0.3235 - val_loss: 2.1956 - val_accuracy: 0.2163\n",
      "Epoch 281/450\n",
      "4896/4896 [==============================] - 1s 270us/step - loss: 1.8422 - accuracy: 0.3272 - val_loss: 2.2302 - val_accuracy: 0.2009\n",
      "Epoch 282/450\n",
      "4896/4896 [==============================] - 1s 238us/step - loss: 1.8292 - accuracy: 0.3237 - val_loss: 2.2730 - val_accuracy: 0.2132\n",
      "Epoch 283/450\n",
      "4896/4896 [==============================] - 1s 256us/step - loss: 1.8219 - accuracy: 0.3299 - val_loss: 2.1944 - val_accuracy: 0.2025\n",
      "Epoch 284/450\n",
      "4896/4896 [==============================] - 1s 252us/step - loss: 1.8335 - accuracy: 0.3205 - val_loss: 2.3734 - val_accuracy: 0.1948\n",
      "Epoch 285/450\n",
      "4896/4896 [==============================] - 1s 255us/step - loss: 1.8220 - accuracy: 0.3252 - val_loss: 2.2175 - val_accuracy: 0.1948\n",
      "Epoch 286/450\n",
      "4896/4896 [==============================] - 1s 266us/step - loss: 1.8172 - accuracy: 0.3264 - val_loss: 2.5184 - val_accuracy: 0.1764\n",
      "Epoch 287/450\n",
      "4896/4896 [==============================] - 1s 287us/step - loss: 1.8085 - accuracy: 0.3295 - val_loss: 3.1006 - val_accuracy: 0.1580\n",
      "Epoch 288/450\n",
      "4896/4896 [==============================] - 1s 281us/step - loss: 1.8509 - accuracy: 0.3192 - val_loss: 2.3236 - val_accuracy: 0.1641\n",
      "Epoch 289/450\n",
      "4896/4896 [==============================] - 1s 281us/step - loss: 1.8179 - accuracy: 0.3233 - val_loss: 2.3153 - val_accuracy: 0.1687\n",
      "Epoch 290/450\n",
      "4896/4896 [==============================] - 1s 261us/step - loss: 1.8056 - accuracy: 0.3272 - val_loss: 2.1928 - val_accuracy: 0.1779\n",
      "Epoch 291/450\n",
      "4896/4896 [==============================] - 2s 316us/step - loss: 1.8276 - accuracy: 0.3243 - val_loss: 2.2867 - val_accuracy: 0.1810\n",
      "Epoch 292/450\n",
      "4896/4896 [==============================] - 1s 256us/step - loss: 1.8274 - accuracy: 0.3231 - val_loss: 2.3150 - val_accuracy: 0.1871\n",
      "Epoch 293/450\n",
      "4896/4896 [==============================] - 1s 282us/step - loss: 1.8209 - accuracy: 0.3290 - val_loss: 2.1965 - val_accuracy: 0.2040\n",
      "Epoch 294/450\n",
      "4896/4896 [==============================] - 1s 268us/step - loss: 1.8181 - accuracy: 0.3199 - val_loss: 2.2014 - val_accuracy: 0.1979\n",
      "Epoch 295/450\n",
      "4896/4896 [==============================] - 1s 247us/step - loss: 1.8014 - accuracy: 0.3462 - val_loss: 2.5760 - val_accuracy: 0.1856\n",
      "Epoch 296/450\n",
      "4896/4896 [==============================] - 1s 285us/step - loss: 1.8471 - accuracy: 0.3103 - val_loss: 2.3908 - val_accuracy: 0.1963\n",
      "Epoch 297/450\n",
      "4896/4896 [==============================] - 1s 272us/step - loss: 1.8392 - accuracy: 0.3252 - val_loss: 2.3271 - val_accuracy: 0.1933\n",
      "Epoch 298/450\n",
      "4896/4896 [==============================] - 1s 288us/step - loss: 1.8167 - accuracy: 0.3227 - val_loss: 2.2914 - val_accuracy: 0.1764\n",
      "Epoch 299/450\n",
      "4896/4896 [==============================] - 1s 294us/step - loss: 1.8171 - accuracy: 0.3282 - val_loss: 2.2459 - val_accuracy: 0.1856\n",
      "Epoch 300/450\n",
      "4896/4896 [==============================] - 1s 276us/step - loss: 1.8226 - accuracy: 0.3211 - val_loss: 2.2316 - val_accuracy: 0.1887\n",
      "Epoch 301/450\n",
      "4896/4896 [==============================] - 1s 248us/step - loss: 1.8406 - accuracy: 0.3201 - val_loss: 2.2578 - val_accuracy: 0.1887\n",
      "Epoch 302/450\n",
      "4896/4896 [==============================] - 1s 252us/step - loss: 1.8196 - accuracy: 0.3188 - val_loss: 2.2346 - val_accuracy: 0.1963\n",
      "Epoch 303/450\n",
      "4896/4896 [==============================] - 1s 252us/step - loss: 1.7967 - accuracy: 0.3344 - val_loss: 2.1890 - val_accuracy: 0.1871\n",
      "Epoch 304/450\n",
      "4896/4896 [==============================] - 1s 252us/step - loss: 1.8220 - accuracy: 0.3192 - val_loss: 2.3650 - val_accuracy: 0.1564\n",
      "Epoch 305/450\n",
      "4896/4896 [==============================] - 1s 253us/step - loss: 1.8302 - accuracy: 0.3219 - val_loss: 2.2180 - val_accuracy: 0.2055\n",
      "Epoch 306/450\n",
      "4896/4896 [==============================] - 1s 251us/step - loss: 1.8043 - accuracy: 0.3382 - val_loss: 2.3147 - val_accuracy: 0.1902\n",
      "Epoch 307/450\n",
      "4896/4896 [==============================] - 1s 259us/step - loss: 1.8509 - accuracy: 0.3227 - val_loss: 2.2216 - val_accuracy: 0.1963\n",
      "Epoch 308/450\n",
      "4896/4896 [==============================] - 1s 252us/step - loss: 1.8107 - accuracy: 0.3268 - val_loss: 2.2323 - val_accuracy: 0.1933\n",
      "Epoch 309/450\n",
      "4896/4896 [==============================] - 1s 242us/step - loss: 1.8145 - accuracy: 0.3270 - val_loss: 2.2429 - val_accuracy: 0.2025\n",
      "Epoch 310/450\n",
      "4896/4896 [==============================] - 1s 252us/step - loss: 1.8201 - accuracy: 0.3260 - val_loss: 2.2275 - val_accuracy: 0.1871\n",
      "Epoch 311/450\n",
      "4896/4896 [==============================] - 1s 275us/step - loss: 1.8152 - accuracy: 0.3246 - val_loss: 2.1913 - val_accuracy: 0.1994\n",
      "Epoch 312/450\n",
      "4896/4896 [==============================] - 1s 241us/step - loss: 1.8245 - accuracy: 0.3307 - val_loss: 2.2678 - val_accuracy: 0.1748\n",
      "Epoch 313/450\n",
      "4896/4896 [==============================] - 1s 254us/step - loss: 1.8218 - accuracy: 0.3295 - val_loss: 2.2394 - val_accuracy: 0.1963\n",
      "Epoch 314/450\n",
      "4896/4896 [==============================] - 1s 243us/step - loss: 1.8157 - accuracy: 0.3172 - val_loss: 2.1920 - val_accuracy: 0.2071\n",
      "Epoch 315/450\n",
      "4896/4896 [==============================] - 1s 240us/step - loss: 1.8315 - accuracy: 0.3231 - val_loss: 2.2898 - val_accuracy: 0.1718\n",
      "Epoch 316/450\n",
      "4896/4896 [==============================] - 1s 243us/step - loss: 1.8145 - accuracy: 0.3331 - val_loss: 2.2643 - val_accuracy: 0.2071\n",
      "Epoch 317/450\n",
      "4896/4896 [==============================] - 1s 245us/step - loss: 1.8085 - accuracy: 0.3262 - val_loss: 2.7735 - val_accuracy: 0.1626\n",
      "Epoch 318/450\n",
      "4896/4896 [==============================] - 1s 242us/step - loss: 1.8230 - accuracy: 0.3288 - val_loss: 2.5473 - val_accuracy: 0.1534\n",
      "Epoch 319/450\n",
      "4896/4896 [==============================] - 1s 267us/step - loss: 1.8326 - accuracy: 0.3250 - val_loss: 2.3145 - val_accuracy: 0.2040\n",
      "Epoch 320/450\n",
      "4896/4896 [==============================] - 1s 253us/step - loss: 1.8105 - accuracy: 0.3270 - val_loss: 2.3043 - val_accuracy: 0.1779\n",
      "Epoch 321/450\n",
      "4896/4896 [==============================] - 1s 256us/step - loss: 1.8309 - accuracy: 0.3186 - val_loss: 2.2669 - val_accuracy: 0.1933\n",
      "Epoch 322/450\n",
      "4896/4896 [==============================] - 1s 253us/step - loss: 1.8274 - accuracy: 0.3188 - val_loss: 2.2648 - val_accuracy: 0.1917\n",
      "Epoch 323/450\n",
      "4896/4896 [==============================] - 1s 253us/step - loss: 1.8079 - accuracy: 0.3295 - val_loss: 2.2382 - val_accuracy: 0.1871\n",
      "Epoch 324/450\n",
      "4896/4896 [==============================] - 1s 249us/step - loss: 1.8240 - accuracy: 0.3152 - val_loss: 2.3045 - val_accuracy: 0.1902\n",
      "Epoch 325/450\n",
      "4896/4896 [==============================] - 1s 252us/step - loss: 1.8169 - accuracy: 0.3252 - val_loss: 2.2446 - val_accuracy: 0.1840\n",
      "Epoch 326/450\n",
      "4896/4896 [==============================] - 1s 256us/step - loss: 1.7885 - accuracy: 0.3350 - val_loss: 2.1902 - val_accuracy: 0.1963\n",
      "Epoch 327/450\n",
      "4896/4896 [==============================] - 1s 250us/step - loss: 1.8427 - accuracy: 0.3309 - val_loss: 2.2566 - val_accuracy: 0.1948\n",
      "Epoch 328/450\n",
      "4896/4896 [==============================] - 1s 248us/step - loss: 1.8023 - accuracy: 0.3382 - val_loss: 2.4404 - val_accuracy: 0.1887\n",
      "Epoch 329/450\n",
      "4896/4896 [==============================] - 1s 263us/step - loss: 1.8087 - accuracy: 0.3264 - val_loss: 2.3090 - val_accuracy: 0.2009\n",
      "Epoch 330/450\n",
      "4896/4896 [==============================] - 1s 259us/step - loss: 1.8825 - accuracy: 0.3252 - val_loss: 2.2083 - val_accuracy: 0.1902\n",
      "Epoch 331/450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4896/4896 [==============================] - 1s 257us/step - loss: 1.8159 - accuracy: 0.3246 - val_loss: 2.3263 - val_accuracy: 0.1948\n",
      "Epoch 332/450\n",
      "4896/4896 [==============================] - 1s 238us/step - loss: 1.8121 - accuracy: 0.3278 - val_loss: 2.1596 - val_accuracy: 0.1933\n",
      "Epoch 333/450\n",
      "4896/4896 [==============================] - 1s 243us/step - loss: 1.8484 - accuracy: 0.3272 - val_loss: 2.2358 - val_accuracy: 0.1948\n",
      "Epoch 334/450\n",
      "4896/4896 [==============================] - 1s 234us/step - loss: 1.7989 - accuracy: 0.3366 - val_loss: 2.3927 - val_accuracy: 0.1687\n",
      "Epoch 335/450\n",
      "4896/4896 [==============================] - 1s 239us/step - loss: 1.8134 - accuracy: 0.3317 - val_loss: 2.2161 - val_accuracy: 0.2040\n",
      "Epoch 336/450\n",
      "4896/4896 [==============================] - 1s 234us/step - loss: 1.8211 - accuracy: 0.3250 - val_loss: 2.3202 - val_accuracy: 0.2101\n",
      "Epoch 337/450\n",
      "4896/4896 [==============================] - 1s 242us/step - loss: 1.8040 - accuracy: 0.3286 - val_loss: 2.2729 - val_accuracy: 0.1994\n",
      "Epoch 338/450\n",
      "4896/4896 [==============================] - 1s 230us/step - loss: 1.8246 - accuracy: 0.3231 - val_loss: 2.2458 - val_accuracy: 0.1887\n",
      "Epoch 339/450\n",
      "4896/4896 [==============================] - 1s 233us/step - loss: 1.8146 - accuracy: 0.3145 - val_loss: 2.3049 - val_accuracy: 0.1902\n",
      "Epoch 340/450\n",
      "4896/4896 [==============================] - 1s 227us/step - loss: 1.7931 - accuracy: 0.3260 - val_loss: 2.2909 - val_accuracy: 0.2040\n",
      "Epoch 341/450\n",
      "4896/4896 [==============================] - 1s 236us/step - loss: 1.8053 - accuracy: 0.3354 - val_loss: 2.4829 - val_accuracy: 0.1902\n",
      "Epoch 342/450\n",
      "4896/4896 [==============================] - 1s 242us/step - loss: 1.8204 - accuracy: 0.3243 - val_loss: 2.1972 - val_accuracy: 0.1963\n",
      "Epoch 343/450\n",
      "4896/4896 [==============================] - 1s 232us/step - loss: 1.7987 - accuracy: 0.3391 - val_loss: 2.6849 - val_accuracy: 0.1702\n",
      "Epoch 344/450\n",
      "4896/4896 [==============================] - 1s 225us/step - loss: 1.8098 - accuracy: 0.3325 - val_loss: 2.2166 - val_accuracy: 0.1887\n",
      "Epoch 345/450\n",
      "4896/4896 [==============================] - 1s 234us/step - loss: 1.7999 - accuracy: 0.3217 - val_loss: 2.4584 - val_accuracy: 0.1856\n",
      "Epoch 346/450\n",
      "4896/4896 [==============================] - 1s 223us/step - loss: 1.8159 - accuracy: 0.3274 - val_loss: 2.3852 - val_accuracy: 0.1733\n",
      "Epoch 347/450\n",
      "4896/4896 [==============================] - 1s 254us/step - loss: 1.8072 - accuracy: 0.3356 - val_loss: 2.2192 - val_accuracy: 0.2101\n",
      "Epoch 348/450\n",
      "4896/4896 [==============================] - 1s 251us/step - loss: 1.8048 - accuracy: 0.3282 - val_loss: 2.3197 - val_accuracy: 0.1825\n",
      "Epoch 349/450\n",
      "4896/4896 [==============================] - 1s 255us/step - loss: 1.8003 - accuracy: 0.3211 - val_loss: 2.3724 - val_accuracy: 0.1825\n",
      "Epoch 350/450\n",
      "4896/4896 [==============================] - 1s 260us/step - loss: 1.8098 - accuracy: 0.3250 - val_loss: 2.2965 - val_accuracy: 0.1764\n",
      "Epoch 351/450\n",
      "4896/4896 [==============================] - 1s 242us/step - loss: 1.7979 - accuracy: 0.3278 - val_loss: 2.1841 - val_accuracy: 0.2163\n",
      "Epoch 352/450\n",
      "4896/4896 [==============================] - 1s 255us/step - loss: 1.8065 - accuracy: 0.3260 - val_loss: 2.4838 - val_accuracy: 0.1764\n",
      "Epoch 353/450\n",
      "4896/4896 [==============================] - 1s 281us/step - loss: 1.8015 - accuracy: 0.3327 - val_loss: 2.4281 - val_accuracy: 0.1687\n",
      "Epoch 354/450\n",
      "4896/4896 [==============================] - 1s 242us/step - loss: 1.8098 - accuracy: 0.3258 - val_loss: 2.2386 - val_accuracy: 0.1963\n",
      "Epoch 355/450\n",
      "4896/4896 [==============================] - 1s 267us/step - loss: 1.8119 - accuracy: 0.3276 - val_loss: 2.2418 - val_accuracy: 0.1687\n",
      "Epoch 356/450\n",
      "4896/4896 [==============================] - 1s 263us/step - loss: 1.8232 - accuracy: 0.3286 - val_loss: 2.2559 - val_accuracy: 0.1856\n",
      "Epoch 357/450\n",
      "4896/4896 [==============================] - 1s 252us/step - loss: 1.8129 - accuracy: 0.3303 - val_loss: 2.2548 - val_accuracy: 0.1887\n",
      "Epoch 358/450\n",
      "4896/4896 [==============================] - 1s 293us/step - loss: 1.7862 - accuracy: 0.3307 - val_loss: 2.2704 - val_accuracy: 0.1871\n",
      "Epoch 359/450\n",
      "4896/4896 [==============================] - 1s 246us/step - loss: 1.8066 - accuracy: 0.3256 - val_loss: 2.2997 - val_accuracy: 0.1840\n",
      "Epoch 360/450\n",
      "4896/4896 [==============================] - 1s 268us/step - loss: 1.7963 - accuracy: 0.3339 - val_loss: 2.2277 - val_accuracy: 0.1902\n",
      "Epoch 361/450\n",
      "4896/4896 [==============================] - 1s 256us/step - loss: 1.8043 - accuracy: 0.3335 - val_loss: 2.3006 - val_accuracy: 0.1825\n",
      "Epoch 362/450\n",
      "4896/4896 [==============================] - 1s 281us/step - loss: 1.8003 - accuracy: 0.3290 - val_loss: 2.3819 - val_accuracy: 0.1825\n",
      "Epoch 363/450\n",
      "4896/4896 [==============================] - 1s 274us/step - loss: 1.8186 - accuracy: 0.3209 - val_loss: 2.2448 - val_accuracy: 0.1994\n",
      "Epoch 364/450\n",
      "4896/4896 [==============================] - 2s 412us/step - loss: 1.8007 - accuracy: 0.3333 - val_loss: 2.2794 - val_accuracy: 0.1748\n",
      "Epoch 365/450\n",
      "4896/4896 [==============================] - 2s 346us/step - loss: 1.7901 - accuracy: 0.3344 - val_loss: 2.3060 - val_accuracy: 0.1810\n",
      "Epoch 366/450\n",
      "4896/4896 [==============================] - 2s 395us/step - loss: 1.8030 - accuracy: 0.3284 - val_loss: 2.2791 - val_accuracy: 0.1887\n",
      "Epoch 367/450\n",
      "4896/4896 [==============================] - 2s 456us/step - loss: 1.8024 - accuracy: 0.3311 - val_loss: 2.3636 - val_accuracy: 0.1856\n",
      "Epoch 368/450\n",
      "4896/4896 [==============================] - 2s 487us/step - loss: 1.7906 - accuracy: 0.3331 - val_loss: 2.4894 - val_accuracy: 0.1794\n",
      "Epoch 369/450\n",
      "4896/4896 [==============================] - 2s 380us/step - loss: 1.8176 - accuracy: 0.3335 - val_loss: 2.3341 - val_accuracy: 0.1871\n",
      "Epoch 370/450\n",
      "4896/4896 [==============================] - 2s 386us/step - loss: 1.7887 - accuracy: 0.3272 - val_loss: 2.6928 - val_accuracy: 0.1840\n",
      "Epoch 371/450\n",
      "4896/4896 [==============================] - 2s 387us/step - loss: 1.7969 - accuracy: 0.3335 - val_loss: 4.5977 - val_accuracy: 0.1488\n",
      "Epoch 372/450\n",
      "4896/4896 [==============================] - 2s 471us/step - loss: 1.8790 - accuracy: 0.3274 - val_loss: 2.3348 - val_accuracy: 0.1994\n",
      "Epoch 373/450\n",
      "4896/4896 [==============================] - 3s 541us/step - loss: 1.7900 - accuracy: 0.3388 - val_loss: 2.4102 - val_accuracy: 0.1810\n",
      "Epoch 374/450\n",
      "4896/4896 [==============================] - 3s 566us/step - loss: 1.8174 - accuracy: 0.3348 - val_loss: 2.4236 - val_accuracy: 0.1733\n",
      "Epoch 375/450\n",
      "4896/4896 [==============================] - 3s 571us/step - loss: 1.7904 - accuracy: 0.3337 - val_loss: 2.4223 - val_accuracy: 0.1856\n",
      "Epoch 376/450\n",
      "4896/4896 [==============================] - 2s 490us/step - loss: 1.7910 - accuracy: 0.3423 - val_loss: 2.2292 - val_accuracy: 0.1856\n",
      "Epoch 377/450\n",
      "4896/4896 [==============================] - 2s 421us/step - loss: 1.8148 - accuracy: 0.3290 - val_loss: 2.2105 - val_accuracy: 0.2071\n",
      "Epoch 378/450\n",
      "4896/4896 [==============================] - 3s 533us/step - loss: 1.7959 - accuracy: 0.3346 - val_loss: 2.2619 - val_accuracy: 0.1963\n",
      "Epoch 379/450\n",
      "4896/4896 [==============================] - 3s 538us/step - loss: 1.8254 - accuracy: 0.3315 - val_loss: 2.2926 - val_accuracy: 0.1963\n",
      "Epoch 380/450\n",
      "4896/4896 [==============================] - 3s 573us/step - loss: 1.7872 - accuracy: 0.3358 - val_loss: 2.3378 - val_accuracy: 0.1871\n",
      "Epoch 381/450\n",
      "4896/4896 [==============================] - 2s 459us/step - loss: 1.7989 - accuracy: 0.3350 - val_loss: 2.2098 - val_accuracy: 0.1963\n",
      "Epoch 382/450\n",
      "4896/4896 [==============================] - 2s 359us/step - loss: 1.7946 - accuracy: 0.3268 - val_loss: 2.3110 - val_accuracy: 0.1595\n",
      "Epoch 383/450\n",
      "4896/4896 [==============================] - 2s 401us/step - loss: 1.7896 - accuracy: 0.3325 - val_loss: 2.2229 - val_accuracy: 0.2071\n",
      "Epoch 384/450\n",
      "4896/4896 [==============================] - 3s 521us/step - loss: 1.8860 - accuracy: 0.3272 - val_loss: 2.5767 - val_accuracy: 0.1810\n",
      "Epoch 385/450\n",
      "4896/4896 [==============================] - 3s 571us/step - loss: 1.8410 - accuracy: 0.3372 - val_loss: 2.2136 - val_accuracy: 0.1948\n",
      "Epoch 386/450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4896/4896 [==============================] - 2s 493us/step - loss: 1.7924 - accuracy: 0.3342 - val_loss: 2.2066 - val_accuracy: 0.2101\n",
      "Epoch 387/450\n",
      "4896/4896 [==============================] - 2s 394us/step - loss: 1.7974 - accuracy: 0.3331 - val_loss: 2.2293 - val_accuracy: 0.1902\n",
      "Epoch 388/450\n",
      "4896/4896 [==============================] - 2s 345us/step - loss: 1.7943 - accuracy: 0.3321 - val_loss: 2.2571 - val_accuracy: 0.1994\n",
      "Epoch 389/450\n",
      "4896/4896 [==============================] - 2s 504us/step - loss: 1.7994 - accuracy: 0.3327 - val_loss: 2.3818 - val_accuracy: 0.1856\n",
      "Epoch 390/450\n",
      "4896/4896 [==============================] - 2s 504us/step - loss: 1.7879 - accuracy: 0.3337 - val_loss: 2.1842 - val_accuracy: 0.1933\n",
      "Epoch 391/450\n",
      "4896/4896 [==============================] - 3s 531us/step - loss: 1.8037 - accuracy: 0.3272 - val_loss: 2.2457 - val_accuracy: 0.1994\n",
      "Epoch 392/450\n",
      "4896/4896 [==============================] - 2s 399us/step - loss: 1.8476 - accuracy: 0.3250 - val_loss: 2.2397 - val_accuracy: 0.1994\n",
      "Epoch 393/450\n",
      "4896/4896 [==============================] - 2s 345us/step - loss: 1.8000 - accuracy: 0.3378 - val_loss: 2.2551 - val_accuracy: 0.1963\n",
      "Epoch 394/450\n",
      "4896/4896 [==============================] - 2s 377us/step - loss: 1.8154 - accuracy: 0.3276 - val_loss: 2.2323 - val_accuracy: 0.1810\n",
      "Epoch 395/450\n",
      "4896/4896 [==============================] - 3s 557us/step - loss: 1.7919 - accuracy: 0.3333 - val_loss: 2.2049 - val_accuracy: 0.2132\n",
      "Epoch 396/450\n",
      "4896/4896 [==============================] - 3s 549us/step - loss: 1.7945 - accuracy: 0.3346 - val_loss: 2.2615 - val_accuracy: 0.2071\n",
      "Epoch 397/450\n",
      "4896/4896 [==============================] - 3s 533us/step - loss: 1.7997 - accuracy: 0.3344 - val_loss: 2.8310 - val_accuracy: 0.1641\n",
      "Epoch 398/450\n",
      "4896/4896 [==============================] - 2s 366us/step - loss: 1.8045 - accuracy: 0.3382 - val_loss: 2.1949 - val_accuracy: 0.1917\n",
      "Epoch 399/450\n",
      "4896/4896 [==============================] - 1s 271us/step - loss: 1.7980 - accuracy: 0.3348 - val_loss: 2.5290 - val_accuracy: 0.1656\n",
      "Epoch 400/450\n",
      "4896/4896 [==============================] - 1s 277us/step - loss: 1.8102 - accuracy: 0.3272 - val_loss: 2.1880 - val_accuracy: 0.2009\n",
      "Epoch 401/450\n",
      "4896/4896 [==============================] - 1s 237us/step - loss: 1.7866 - accuracy: 0.3321 - val_loss: 2.2673 - val_accuracy: 0.2055\n",
      "Epoch 402/450\n",
      "4896/4896 [==============================] - 1s 262us/step - loss: 1.7834 - accuracy: 0.3384 - val_loss: 2.7384 - val_accuracy: 0.1442\n",
      "Epoch 403/450\n",
      "4896/4896 [==============================] - 1s 277us/step - loss: 1.8170 - accuracy: 0.3335 - val_loss: 2.2559 - val_accuracy: 0.2117\n",
      "Epoch 404/450\n",
      "4896/4896 [==============================] - 1s 258us/step - loss: 1.7907 - accuracy: 0.3348 - val_loss: 2.4327 - val_accuracy: 0.1764\n",
      "Epoch 405/450\n",
      "4896/4896 [==============================] - 1s 287us/step - loss: 1.8009 - accuracy: 0.3303 - val_loss: 2.5464 - val_accuracy: 0.1580\n",
      "Epoch 406/450\n",
      "4896/4896 [==============================] - 1s 226us/step - loss: 1.7928 - accuracy: 0.3203 - val_loss: 2.3555 - val_accuracy: 0.1948\n",
      "Epoch 407/450\n",
      "4896/4896 [==============================] - 1s 232us/step - loss: 1.7921 - accuracy: 0.3264 - val_loss: 2.3465 - val_accuracy: 0.1702\n",
      "Epoch 408/450\n",
      "4896/4896 [==============================] - 1s 229us/step - loss: 1.7896 - accuracy: 0.3329 - val_loss: 2.2816 - val_accuracy: 0.2101\n",
      "Epoch 409/450\n",
      "4896/4896 [==============================] - 1s 232us/step - loss: 1.7907 - accuracy: 0.3448 - val_loss: 2.2792 - val_accuracy: 0.2025\n",
      "Epoch 410/450\n",
      "4896/4896 [==============================] - 1s 230us/step - loss: 1.7842 - accuracy: 0.3333 - val_loss: 2.2997 - val_accuracy: 0.2163\n",
      "Epoch 411/450\n",
      "4896/4896 [==============================] - 1s 235us/step - loss: 1.7982 - accuracy: 0.3299 - val_loss: 2.2189 - val_accuracy: 0.1917\n",
      "Epoch 412/450\n",
      "4896/4896 [==============================] - 1s 232us/step - loss: 1.7939 - accuracy: 0.3352 - val_loss: 2.2341 - val_accuracy: 0.1933\n",
      "Epoch 413/450\n",
      "4896/4896 [==============================] - 1s 229us/step - loss: 1.7938 - accuracy: 0.3342 - val_loss: 2.2045 - val_accuracy: 0.2025\n",
      "Epoch 414/450\n",
      "4896/4896 [==============================] - 1s 229us/step - loss: 1.8004 - accuracy: 0.3266 - val_loss: 2.2779 - val_accuracy: 0.1825\n",
      "Epoch 415/450\n",
      "4896/4896 [==============================] - 1s 230us/step - loss: 1.7645 - accuracy: 0.3409 - val_loss: 2.7241 - val_accuracy: 0.1457\n",
      "Epoch 416/450\n",
      "4896/4896 [==============================] - 1s 240us/step - loss: 1.7896 - accuracy: 0.3395 - val_loss: 2.4275 - val_accuracy: 0.1748\n",
      "Epoch 417/450\n",
      "4896/4896 [==============================] - 1s 261us/step - loss: 1.7846 - accuracy: 0.3370 - val_loss: 2.2366 - val_accuracy: 0.2055\n",
      "Epoch 418/450\n",
      "4896/4896 [==============================] - 1s 260us/step - loss: 1.8280 - accuracy: 0.3233 - val_loss: 2.3383 - val_accuracy: 0.1963\n",
      "Epoch 419/450\n",
      "4896/4896 [==============================] - 2s 373us/step - loss: 1.7711 - accuracy: 0.3399 - val_loss: 2.4558 - val_accuracy: 0.1917\n",
      "Epoch 420/450\n",
      "4896/4896 [==============================] - 2s 498us/step - loss: 1.7911 - accuracy: 0.3333 - val_loss: 2.2497 - val_accuracy: 0.1902\n",
      "Epoch 421/450\n",
      "4896/4896 [==============================] - 3s 542us/step - loss: 1.8086 - accuracy: 0.3266 - val_loss: 2.4171 - val_accuracy: 0.1963\n",
      "Epoch 422/450\n",
      "4896/4896 [==============================] - 2s 501us/step - loss: 1.7867 - accuracy: 0.3350 - val_loss: 2.2567 - val_accuracy: 0.1840\n",
      "Epoch 423/450\n",
      "4896/4896 [==============================] - 2s 368us/step - loss: 1.7849 - accuracy: 0.3317 - val_loss: 2.4222 - val_accuracy: 0.1779\n",
      "Epoch 424/450\n",
      "4896/4896 [==============================] - 1s 284us/step - loss: 1.7891 - accuracy: 0.3305 - val_loss: 2.2536 - val_accuracy: 0.1994\n",
      "Epoch 425/450\n",
      "4896/4896 [==============================] - 1s 228us/step - loss: 1.8185 - accuracy: 0.3444 - val_loss: 2.1719 - val_accuracy: 0.1840\n",
      "Epoch 426/450\n",
      "4896/4896 [==============================] - 1s 228us/step - loss: 1.8005 - accuracy: 0.3329 - val_loss: 2.1805 - val_accuracy: 0.2101\n",
      "Epoch 427/450\n",
      "4896/4896 [==============================] - 1s 235us/step - loss: 1.8256 - accuracy: 0.3356 - val_loss: 2.5172 - val_accuracy: 0.1810\n",
      "Epoch 428/450\n",
      "4896/4896 [==============================] - 1s 249us/step - loss: 1.7721 - accuracy: 0.3319 - val_loss: 2.3913 - val_accuracy: 0.1856\n",
      "Epoch 429/450\n",
      "4896/4896 [==============================] - 1s 232us/step - loss: 1.8001 - accuracy: 0.3241 - val_loss: 2.2795 - val_accuracy: 0.2086\n",
      "Epoch 430/450\n",
      "4896/4896 [==============================] - 1s 237us/step - loss: 1.7777 - accuracy: 0.3411 - val_loss: 2.2095 - val_accuracy: 0.1902\n",
      "Epoch 431/450\n",
      "4896/4896 [==============================] - 1s 265us/step - loss: 1.7886 - accuracy: 0.3335 - val_loss: 2.3108 - val_accuracy: 0.1917\n",
      "Epoch 432/450\n",
      "4896/4896 [==============================] - 1s 249us/step - loss: 1.7864 - accuracy: 0.3356 - val_loss: 2.2511 - val_accuracy: 0.1948\n",
      "Epoch 433/450\n",
      "4896/4896 [==============================] - 1s 258us/step - loss: 1.7831 - accuracy: 0.3352 - val_loss: 2.2142 - val_accuracy: 0.2086\n",
      "Epoch 434/450\n",
      "4896/4896 [==============================] - 1s 251us/step - loss: 1.7775 - accuracy: 0.3350 - val_loss: 2.1981 - val_accuracy: 0.2040\n",
      "Epoch 435/450\n",
      "4896/4896 [==============================] - 1s 266us/step - loss: 1.7664 - accuracy: 0.3442 - val_loss: 2.3369 - val_accuracy: 0.2025\n",
      "Epoch 436/450\n",
      "4896/4896 [==============================] - 1s 257us/step - loss: 1.7835 - accuracy: 0.3427 - val_loss: 2.5930 - val_accuracy: 0.1534\n",
      "Epoch 437/450\n",
      "4896/4896 [==============================] - 1s 269us/step - loss: 1.8007 - accuracy: 0.3256 - val_loss: 2.2736 - val_accuracy: 0.1994\n",
      "Epoch 438/450\n",
      "4896/4896 [==============================] - 1s 241us/step - loss: 1.7867 - accuracy: 0.3327 - val_loss: 2.3405 - val_accuracy: 0.1994\n",
      "Epoch 439/450\n",
      "4896/4896 [==============================] - 1s 248us/step - loss: 1.7762 - accuracy: 0.3444 - val_loss: 2.2245 - val_accuracy: 0.2132\n",
      "Epoch 440/450\n",
      "4896/4896 [==============================] - 1s 289us/step - loss: 1.7783 - accuracy: 0.3452 - val_loss: 2.3627 - val_accuracy: 0.1794\n",
      "Epoch 441/450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4896/4896 [==============================] - 2s 443us/step - loss: 1.7736 - accuracy: 0.3421 - val_loss: 2.2646 - val_accuracy: 0.1887\n",
      "Epoch 442/450\n",
      "4896/4896 [==============================] - 3s 517us/step - loss: 1.7931 - accuracy: 0.3346 - val_loss: 2.2505 - val_accuracy: 0.1963\n",
      "Epoch 443/450\n",
      "4896/4896 [==============================] - 2s 496us/step - loss: 1.7811 - accuracy: 0.3354 - val_loss: 2.4232 - val_accuracy: 0.1810\n",
      "Epoch 444/450\n",
      "4896/4896 [==============================] - 2s 485us/step - loss: 1.7747 - accuracy: 0.3407 - val_loss: 2.2355 - val_accuracy: 0.2101\n",
      "Epoch 445/450\n",
      "4896/4896 [==============================] - 2s 341us/step - loss: 1.7838 - accuracy: 0.3339 - val_loss: 2.2257 - val_accuracy: 0.2117\n",
      "Epoch 446/450\n",
      "4896/4896 [==============================] - 1s 269us/step - loss: 1.7760 - accuracy: 0.3423 - val_loss: 2.2551 - val_accuracy: 0.1887\n",
      "Epoch 447/450\n",
      "4896/4896 [==============================] - 1s 272us/step - loss: 1.7856 - accuracy: 0.3384 - val_loss: 2.5995 - val_accuracy: 0.1810\n",
      "Epoch 448/450\n",
      "4896/4896 [==============================] - 1s 261us/step - loss: 1.7929 - accuracy: 0.3342 - val_loss: 2.2178 - val_accuracy: 0.2040\n",
      "Epoch 449/450\n",
      "4896/4896 [==============================] - 1s 236us/step - loss: 1.7833 - accuracy: 0.3405 - val_loss: 2.3443 - val_accuracy: 0.1840\n",
      "Epoch 450/450\n",
      "4896/4896 [==============================] - 2s 312us/step - loss: 1.7746 - accuracy: 0.3337 - val_loss: 2.3097 - val_accuracy: 0.2025\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 450\n",
    "\n",
    "H = classifier.fit(x_train, lab_esc_train,\n",
    "                  epochs = EPOCHS,\n",
    "                  batch_size = 128,\n",
    "                  shuffle = True,\n",
    "                  validation_data=(x_val, lab_esc_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the netowrk - display network stats and save plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training loss and accuracy for each epoch\n",
    "N = np.arange(0, EPOCHS)\n",
    "plt.figure()\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(N, H.history[\"accuracy\"], label=\"train_accuracy\")\n",
    "plt.plot(N, H.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.title(\"Predicting Redshift model 2\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(\"training_perf_250_arch_03.4.75_pred_redshift_with_encoder.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save(\"keras_arch_05.4.75_with_encoder_esc_predict.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(980, 12) (980, 12)\n"
     ]
    }
   ],
   "source": [
    "pred  = classifier.predict(x_test)\n",
    "print(pred.shape, lab_esc_test.shape)\n",
    "l = len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.673469387755102\n"
     ]
    }
   ],
   "source": [
    "ri,wr=0,0\n",
    "for i in range(len(pred)):\n",
    "    a = list(pred[i]).index(max(pred[i]))\n",
    "    b = list(lab_esc_test[i]).index(1)\n",
    "    if a==b: ri+=1\n",
    "    else: wr +=1\n",
    "print(100.0*ri / (ri+wr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'right' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-df617d8d3760>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m print(\"percent correctly classified\\n\",\n\u001b[0;32m----> 2\u001b[0;31m      100.0*float(right)/count)\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'right' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"percent correctly classified\\n\",\n",
    "     100.0*float(right)/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
