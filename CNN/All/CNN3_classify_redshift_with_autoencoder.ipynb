{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras is using tensorflow as the backend\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import sklearn\n",
    "import random\n",
    "import os, sys\n",
    "\n",
    "# import keras\n",
    "import keras\n",
    "from keras import backend as K\n",
    "backend_keras = keras.backend.backend()\n",
    "print(\"keras is using\", backend_keras, \"as the backend\")\n",
    "from keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model, load_model, Sequential\n",
    "\n",
    "# optimizers \n",
    "from keras.optimizers import SGD, Nadam, Adamax, Adam, Adadelta, Adagrad, RMSprop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load redshift data and labels\n",
    "These are the ones which have been created with the keras notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints\n",
      "CNN3_classify_redshift_with_autoencoder.ipynb\n",
      "CNN4_classify_esc_frac_direct_cnn.ipynb\n",
      "CNN4_classify_esc_frac_with_autoencoder.ipynb\n",
      "CNN5_classify_redshift_direct_cnn.ipynb\n",
      "big_mix_data_6528.npy\n",
      "big_mix_labels_6528.npy\n",
      "data_test.npy\n",
      "data_train.npy\n",
      "data_val.npy\n",
      "labels_test.npy\n",
      "labels_train.npy\n",
      "labels_val.npy\n",
      "preprocessing.ipynb\n"
     ]
    }
   ],
   "source": [
    "f = os.listdir()\n",
    "f.sort()\n",
    "for i in f: print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes : (4896, 200, 200, 1) (652, 200, 200, 1) (980, 200, 200, 1)\n",
      "more shape : (4896, 17) (652, 17) (980, 17)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "x_train_raw = np.load(\"data_train.npy\")\n",
    "x_val_raw = np.load(\"data_val.npy\")\n",
    "x_test_raw = np.load(\"data_test.npy\")\n",
    "\n",
    "# load labels\n",
    "labels_train = np.load(\"labels_train.npy\",allow_pickle=True)\n",
    "labels_val = np.load(\"labels_val.npy\",allow_pickle=True)\n",
    "labels_test = np.load(\"labels_test.npy\",allow_pickle=True)\n",
    "\n",
    "# we only care about the redshift labels here\n",
    "lab_red_train = np.array([i[1] for i in labels_train])\n",
    "lab_red_val = np.array([i[1] for i in labels_val])\n",
    "lab_red_test = np.array([i[1] for i in labels_test])\n",
    "\n",
    "print(\"shapes :\", x_train_raw.shape, x_val_raw.shape, x_test_raw.shape)\n",
    "print(\"more shape :\", lab_red_train.shape, lab_red_val.shape, lab_red_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Autoencoder\n",
    "## first load the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"../../Auto-Encoder Training/\")\n",
    "autoencoder = load_model(\"../../Auto-Encoder Training/autoencoder_adam_95.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200, 200, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 200, 200, 16)      160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 100, 100, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 100, 100, 8)       1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 50, 50, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 50, 50, 8)         584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 25, 25, 8)         0         \n",
      "=================================================================\n",
      "Total params: 1,904\n",
      "Trainable params: 1,904\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#autoencoder.summary()\n",
    "encoder = Model(autoencoder.input, autoencoder.layers[-8].output)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = encoder.predict(x_train_raw)\n",
    "x_val = encoder.predict(x_val_raw)\n",
    "x_test = encoder.predict(x_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "# extract features\n",
    "classifier.add(Conv2D(16, (3,3), input_shape=(25,25,8),\n",
    "                     activation='relu', padding='valid'))\n",
    "# reduce dimensionality, keep most important info\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# add a second layer, again with no padding\n",
    "classifier.add(Conv2D(8, (3,3), activation='relu', padding='valid'))\n",
    "\n",
    "# pool again\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# here i flatten and then guess the class\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# fully connected layers ensures connections to all activations \n",
    "# in previous layers\n",
    "\n",
    "classifier.add(Dense(units=17, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative Architecutre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper params + compile netowrk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing summary of model\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 23, 23, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 11, 11, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 9, 9, 8)           1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 17)                2193      \n",
      "=================================================================\n",
      "Total params: 4,521\n",
      "Trainable params: 4,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "opt = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999,\n",
    "          amsgrad=True)\n",
    "\n",
    "classifier.compile(optimizer=opt,\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=[\"accuracy\"])\n",
    "print(\"printing summary of model\")\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4896, 25, 25, 8) (4896, 17)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, lab_red_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display netowrk stats and save plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4896 samples, validate on 652 samples\n",
      "Epoch 1/250\n",
      "4896/4896 [==============================] - 1s 224us/step - loss: 2.8092 - accuracy: 0.0956 - val_loss: 2.6696 - val_accuracy: 0.1104\n",
      "Epoch 2/250\n",
      "4896/4896 [==============================] - 1s 199us/step - loss: 2.3892 - accuracy: 0.1183 - val_loss: 2.1575 - val_accuracy: 0.1564\n",
      "Epoch 3/250\n",
      "4896/4896 [==============================] - 1s 206us/step - loss: 1.8998 - accuracy: 0.2516 - val_loss: 1.7028 - val_accuracy: 0.3589\n",
      "Epoch 4/250\n",
      "4896/4896 [==============================] - 1s 200us/step - loss: 1.5313 - accuracy: 0.4383 - val_loss: 1.4124 - val_accuracy: 0.4540\n",
      "Epoch 5/250\n",
      "4896/4896 [==============================] - 1s 192us/step - loss: 1.2979 - accuracy: 0.5088 - val_loss: 1.2357 - val_accuracy: 0.5276\n",
      "Epoch 6/250\n",
      "4896/4896 [==============================] - 1s 193us/step - loss: 1.1582 - accuracy: 0.5684 - val_loss: 1.1314 - val_accuracy: 0.5859\n",
      "Epoch 7/250\n",
      "4896/4896 [==============================] - 1s 201us/step - loss: 1.0601 - accuracy: 0.5831 - val_loss: 1.0255 - val_accuracy: 0.5859\n",
      "Epoch 8/250\n",
      "4896/4896 [==============================] - 1s 214us/step - loss: 0.9994 - accuracy: 0.5954 - val_loss: 0.9881 - val_accuracy: 0.5660\n",
      "Epoch 9/250\n",
      "4896/4896 [==============================] - 2s 311us/step - loss: 0.9336 - accuracy: 0.6326 - val_loss: 0.9092 - val_accuracy: 0.6641\n",
      "Epoch 10/250\n",
      "4896/4896 [==============================] - 2s 371us/step - loss: 0.8789 - accuracy: 0.6675 - val_loss: 0.9062 - val_accuracy: 0.6273\n",
      "Epoch 11/250\n",
      "4896/4896 [==============================] - 2s 318us/step - loss: 0.8596 - accuracy: 0.6556 - val_loss: 0.8196 - val_accuracy: 0.7163\n",
      "Epoch 12/250\n",
      "4896/4896 [==============================] - 1s 302us/step - loss: 0.8148 - accuracy: 0.6865 - val_loss: 0.7791 - val_accuracy: 0.7117\n",
      "Epoch 13/250\n",
      "4896/4896 [==============================] - 1s 297us/step - loss: 0.7909 - accuracy: 0.6897 - val_loss: 0.8077 - val_accuracy: 0.6840\n",
      "Epoch 14/250\n",
      "4896/4896 [==============================] - 1s 297us/step - loss: 0.7726 - accuracy: 0.6908 - val_loss: 0.7452 - val_accuracy: 0.7117\n",
      "Epoch 15/250\n",
      "4896/4896 [==============================] - 1s 304us/step - loss: 0.7554 - accuracy: 0.6967 - val_loss: 0.7108 - val_accuracy: 0.7469\n",
      "Epoch 16/250\n",
      "4896/4896 [==============================] - 2s 309us/step - loss: 0.7442 - accuracy: 0.7083 - val_loss: 0.7049 - val_accuracy: 0.7515\n",
      "Epoch 17/250\n",
      "4896/4896 [==============================] - 2s 315us/step - loss: 0.7150 - accuracy: 0.7143 - val_loss: 0.7265 - val_accuracy: 0.6979\n",
      "Epoch 18/250\n",
      "4896/4896 [==============================] - 2s 307us/step - loss: 0.7138 - accuracy: 0.7157 - val_loss: 0.7091 - val_accuracy: 0.7255\n",
      "Epoch 19/250\n",
      "4896/4896 [==============================] - 2s 307us/step - loss: 0.6887 - accuracy: 0.7200 - val_loss: 0.6563 - val_accuracy: 0.7515\n",
      "Epoch 20/250\n",
      "4896/4896 [==============================] - 1s 305us/step - loss: 0.6830 - accuracy: 0.7204 - val_loss: 0.6837 - val_accuracy: 0.7239\n",
      "Epoch 21/250\n",
      "4896/4896 [==============================] - 2s 307us/step - loss: 0.6900 - accuracy: 0.7159 - val_loss: 0.6571 - val_accuracy: 0.7301\n",
      "Epoch 22/250\n",
      "4896/4896 [==============================] - 2s 360us/step - loss: 0.6675 - accuracy: 0.7200 - val_loss: 0.6686 - val_accuracy: 0.7193\n",
      "Epoch 23/250\n",
      "4896/4896 [==============================] - 2s 320us/step - loss: 0.6661 - accuracy: 0.7234 - val_loss: 0.6316 - val_accuracy: 0.7577\n",
      "Epoch 24/250\n",
      "4896/4896 [==============================] - 2s 314us/step - loss: 0.6413 - accuracy: 0.7292 - val_loss: 0.6721 - val_accuracy: 0.7117\n",
      "Epoch 25/250\n",
      "4896/4896 [==============================] - 2s 316us/step - loss: 0.6468 - accuracy: 0.7290 - val_loss: 0.6313 - val_accuracy: 0.7561\n",
      "Epoch 26/250\n",
      "4896/4896 [==============================] - 1s 302us/step - loss: 0.6343 - accuracy: 0.7292 - val_loss: 0.6490 - val_accuracy: 0.7086\n",
      "Epoch 27/250\n",
      "4896/4896 [==============================] - 2s 307us/step - loss: 0.6419 - accuracy: 0.7283 - val_loss: 0.6553 - val_accuracy: 0.7101\n",
      "Epoch 28/250\n",
      "4896/4896 [==============================] - 2s 311us/step - loss: 0.6319 - accuracy: 0.7337 - val_loss: 0.6195 - val_accuracy: 0.7469\n",
      "Epoch 29/250\n",
      "4896/4896 [==============================] - 2s 307us/step - loss: 0.6284 - accuracy: 0.7314 - val_loss: 0.6334 - val_accuracy: 0.7239\n",
      "Epoch 30/250\n",
      "4896/4896 [==============================] - 1s 305us/step - loss: 0.6275 - accuracy: 0.7283 - val_loss: 0.6846 - val_accuracy: 0.6963\n",
      "Epoch 31/250\n",
      "4896/4896 [==============================] - 1s 300us/step - loss: 0.6127 - accuracy: 0.7347 - val_loss: 0.5826 - val_accuracy: 0.7592\n",
      "Epoch 32/250\n",
      "4896/4896 [==============================] - 1s 298us/step - loss: 0.6151 - accuracy: 0.7375 - val_loss: 0.5972 - val_accuracy: 0.7515\n",
      "Epoch 33/250\n",
      "4896/4896 [==============================] - 1s 302us/step - loss: 0.5897 - accuracy: 0.7414 - val_loss: 0.6070 - val_accuracy: 0.7500\n",
      "Epoch 34/250\n",
      "4896/4896 [==============================] - 1s 300us/step - loss: 0.6117 - accuracy: 0.7347 - val_loss: 0.5706 - val_accuracy: 0.7761\n",
      "Epoch 35/250\n",
      "4896/4896 [==============================] - 2s 311us/step - loss: 0.6210 - accuracy: 0.7281 - val_loss: 0.5921 - val_accuracy: 0.7454\n",
      "Epoch 36/250\n",
      "4896/4896 [==============================] - 1s 296us/step - loss: 0.5954 - accuracy: 0.7459 - val_loss: 0.5809 - val_accuracy: 0.7577\n",
      "Epoch 37/250\n",
      "4896/4896 [==============================] - 1s 299us/step - loss: 0.5846 - accuracy: 0.7441 - val_loss: 0.5823 - val_accuracy: 0.7715\n",
      "Epoch 38/250\n",
      "4896/4896 [==============================] - 1s 298us/step - loss: 0.5823 - accuracy: 0.7429 - val_loss: 0.5609 - val_accuracy: 0.7423\n",
      "Epoch 39/250\n",
      "4896/4896 [==============================] - 2s 314us/step - loss: 0.5720 - accuracy: 0.7469 - val_loss: 0.5840 - val_accuracy: 0.7531\n",
      "Epoch 40/250\n",
      "4896/4896 [==============================] - 1s 304us/step - loss: 0.5726 - accuracy: 0.7473 - val_loss: 0.5720 - val_accuracy: 0.7730\n",
      "Epoch 41/250\n",
      "4896/4896 [==============================] - 1s 295us/step - loss: 0.5785 - accuracy: 0.7439 - val_loss: 0.5723 - val_accuracy: 0.7485\n",
      "Epoch 42/250\n",
      "4896/4896 [==============================] - 2s 310us/step - loss: 0.5745 - accuracy: 0.7420 - val_loss: 0.6234 - val_accuracy: 0.7132\n",
      "Epoch 43/250\n",
      "4896/4896 [==============================] - 2s 310us/step - loss: 0.5781 - accuracy: 0.7443 - val_loss: 0.5841 - val_accuracy: 0.7592\n",
      "Epoch 44/250\n",
      "4896/4896 [==============================] - 1s 299us/step - loss: 0.5808 - accuracy: 0.7498 - val_loss: 0.5774 - val_accuracy: 0.7515\n",
      "Epoch 45/250\n",
      "4896/4896 [==============================] - 1s 304us/step - loss: 0.5600 - accuracy: 0.7541 - val_loss: 0.5524 - val_accuracy: 0.7546\n",
      "Epoch 46/250\n",
      "4896/4896 [==============================] - 1s 297us/step - loss: 0.5613 - accuracy: 0.7478 - val_loss: 0.5434 - val_accuracy: 0.7607\n",
      "Epoch 47/250\n",
      "4896/4896 [==============================] - 2s 353us/step - loss: 0.5545 - accuracy: 0.7555 - val_loss: 0.5516 - val_accuracy: 0.7776\n",
      "Epoch 48/250\n",
      "4896/4896 [==============================] - 2s 316us/step - loss: 0.5588 - accuracy: 0.7449 - val_loss: 0.5403 - val_accuracy: 0.7730\n",
      "Epoch 49/250\n",
      "4896/4896 [==============================] - 2s 321us/step - loss: 0.5498 - accuracy: 0.7525 - val_loss: 0.5645 - val_accuracy: 0.7408\n",
      "Epoch 50/250\n",
      "4896/4896 [==============================] - 2s 325us/step - loss: 0.5429 - accuracy: 0.7510 - val_loss: 0.5516 - val_accuracy: 0.7807\n",
      "Epoch 51/250\n",
      "4896/4896 [==============================] - 1s 299us/step - loss: 0.5727 - accuracy: 0.7506 - val_loss: 0.5291 - val_accuracy: 0.7592\n",
      "Epoch 52/250\n",
      "4896/4896 [==============================] - 1s 304us/step - loss: 0.5478 - accuracy: 0.7506 - val_loss: 0.5381 - val_accuracy: 0.7761\n",
      "Epoch 53/250\n",
      "4896/4896 [==============================] - 1s 296us/step - loss: 0.5388 - accuracy: 0.7610 - val_loss: 0.5557 - val_accuracy: 0.7669\n",
      "Epoch 54/250\n",
      "4896/4896 [==============================] - 1s 299us/step - loss: 0.5430 - accuracy: 0.7549 - val_loss: 0.5260 - val_accuracy: 0.7515\n",
      "Epoch 55/250\n",
      "4896/4896 [==============================] - 2s 313us/step - loss: 0.5549 - accuracy: 0.7543 - val_loss: 0.5344 - val_accuracy: 0.7730\n",
      "Epoch 56/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4896/4896 [==============================] - 1s 292us/step - loss: 0.5390 - accuracy: 0.7574 - val_loss: 0.5697 - val_accuracy: 0.7546\n",
      "Epoch 57/250\n",
      "4896/4896 [==============================] - 1s 288us/step - loss: 0.5523 - accuracy: 0.7529 - val_loss: 0.5327 - val_accuracy: 0.7607\n",
      "Epoch 58/250\n",
      "4896/4896 [==============================] - 1s 290us/step - loss: 0.5389 - accuracy: 0.7623 - val_loss: 0.5771 - val_accuracy: 0.7561\n",
      "Epoch 59/250\n",
      "4896/4896 [==============================] - 1s 300us/step - loss: 0.5420 - accuracy: 0.7535 - val_loss: 0.5486 - val_accuracy: 0.7684\n",
      "Epoch 60/250\n",
      "4896/4896 [==============================] - 1s 289us/step - loss: 0.5443 - accuracy: 0.7600 - val_loss: 0.5568 - val_accuracy: 0.7607\n",
      "Epoch 61/250\n",
      "4896/4896 [==============================] - 1s 286us/step - loss: 0.5385 - accuracy: 0.7559 - val_loss: 0.5441 - val_accuracy: 0.7423\n",
      "Epoch 62/250\n",
      "4896/4896 [==============================] - 1s 293us/step - loss: 0.5358 - accuracy: 0.7486 - val_loss: 0.5234 - val_accuracy: 0.7699\n",
      "Epoch 63/250\n",
      "4896/4896 [==============================] - 2s 308us/step - loss: 0.5367 - accuracy: 0.7551 - val_loss: 0.6125 - val_accuracy: 0.7270\n",
      "Epoch 64/250\n",
      "4896/4896 [==============================] - 1s 304us/step - loss: 0.5396 - accuracy: 0.7535 - val_loss: 0.5403 - val_accuracy: 0.7669\n",
      "Epoch 65/250\n",
      "4896/4896 [==============================] - 2s 330us/step - loss: 0.5221 - accuracy: 0.7686 - val_loss: 0.5452 - val_accuracy: 0.7607\n",
      "Epoch 66/250\n",
      "4896/4896 [==============================] - 1s 294us/step - loss: 0.5102 - accuracy: 0.7700 - val_loss: 0.5360 - val_accuracy: 0.7669\n",
      "Epoch 67/250\n",
      "4896/4896 [==============================] - 1s 294us/step - loss: 0.5279 - accuracy: 0.7557 - val_loss: 0.5288 - val_accuracy: 0.7684\n",
      "Epoch 68/250\n",
      "4896/4896 [==============================] - 1s 289us/step - loss: 0.5213 - accuracy: 0.7639 - val_loss: 0.5038 - val_accuracy: 0.7776\n",
      "Epoch 69/250\n",
      "4896/4896 [==============================] - 1s 282us/step - loss: 0.5239 - accuracy: 0.7627 - val_loss: 0.5469 - val_accuracy: 0.7531\n",
      "Epoch 70/250\n",
      "4896/4896 [==============================] - 1s 301us/step - loss: 0.5196 - accuracy: 0.7629 - val_loss: 0.5929 - val_accuracy: 0.7285\n",
      "Epoch 71/250\n",
      "4896/4896 [==============================] - 1s 300us/step - loss: 0.5355 - accuracy: 0.7539 - val_loss: 0.5527 - val_accuracy: 0.7347\n",
      "Epoch 72/250\n",
      "4896/4896 [==============================] - 1s 285us/step - loss: 0.5198 - accuracy: 0.7616 - val_loss: 0.5022 - val_accuracy: 0.7653\n",
      "Epoch 73/250\n",
      "4896/4896 [==============================] - 1s 305us/step - loss: 0.5124 - accuracy: 0.7637 - val_loss: 0.5068 - val_accuracy: 0.7791\n",
      "Epoch 74/250\n",
      "4896/4896 [==============================] - 1s 296us/step - loss: 0.5182 - accuracy: 0.7623 - val_loss: 0.5071 - val_accuracy: 0.7745\n",
      "Epoch 75/250\n",
      "4896/4896 [==============================] - 1s 300us/step - loss: 0.5118 - accuracy: 0.7621 - val_loss: 0.5175 - val_accuracy: 0.7791\n",
      "Epoch 76/250\n",
      "4896/4896 [==============================] - 1s 292us/step - loss: 0.5271 - accuracy: 0.7635 - val_loss: 0.5171 - val_accuracy: 0.7776\n",
      "Epoch 77/250\n",
      "4896/4896 [==============================] - 1s 288us/step - loss: 0.5061 - accuracy: 0.7714 - val_loss: 0.5146 - val_accuracy: 0.7868\n",
      "Epoch 78/250\n",
      "4896/4896 [==============================] - 1s 290us/step - loss: 0.4989 - accuracy: 0.7678 - val_loss: 0.4923 - val_accuracy: 0.7914\n",
      "Epoch 79/250\n",
      "4896/4896 [==============================] - 1s 286us/step - loss: 0.4988 - accuracy: 0.7663 - val_loss: 0.5112 - val_accuracy: 0.7761\n",
      "Epoch 80/250\n",
      "4896/4896 [==============================] - 1s 285us/step - loss: 0.4966 - accuracy: 0.7698 - val_loss: 0.4900 - val_accuracy: 0.7715\n",
      "Epoch 81/250\n",
      "4896/4896 [==============================] - 1s 296us/step - loss: 0.5000 - accuracy: 0.7714 - val_loss: 0.4938 - val_accuracy: 0.7853\n",
      "Epoch 82/250\n",
      "4896/4896 [==============================] - 1s 298us/step - loss: 0.5132 - accuracy: 0.7682 - val_loss: 0.4787 - val_accuracy: 0.7929\n",
      "Epoch 83/250\n",
      "4896/4896 [==============================] - 1s 295us/step - loss: 0.4998 - accuracy: 0.7684 - val_loss: 0.4832 - val_accuracy: 0.7791\n",
      "Epoch 84/250\n",
      "4896/4896 [==============================] - 1s 287us/step - loss: 0.5036 - accuracy: 0.7676 - val_loss: 0.4908 - val_accuracy: 0.7975\n",
      "Epoch 85/250\n",
      "4896/4896 [==============================] - 1s 293us/step - loss: 0.4897 - accuracy: 0.7739 - val_loss: 0.4869 - val_accuracy: 0.7699\n",
      "Epoch 86/250\n",
      "4896/4896 [==============================] - 1s 304us/step - loss: 0.4864 - accuracy: 0.7678 - val_loss: 0.5123 - val_accuracy: 0.7975\n",
      "Epoch 87/250\n",
      "4896/4896 [==============================] - 2s 354us/step - loss: 0.5048 - accuracy: 0.7714 - val_loss: 0.6171 - val_accuracy: 0.6994\n",
      "Epoch 88/250\n",
      "4896/4896 [==============================] - 2s 327us/step - loss: 0.5063 - accuracy: 0.7635 - val_loss: 0.4866 - val_accuracy: 0.7945\n",
      "Epoch 89/250\n",
      "4896/4896 [==============================] - 1s 303us/step - loss: 0.4925 - accuracy: 0.7745 - val_loss: 0.5023 - val_accuracy: 0.7791\n",
      "Epoch 90/250\n",
      "4896/4896 [==============================] - 2s 315us/step - loss: 0.4830 - accuracy: 0.7766 - val_loss: 0.5008 - val_accuracy: 0.7592\n",
      "Epoch 91/250\n",
      "4896/4896 [==============================] - 2s 335us/step - loss: 0.4769 - accuracy: 0.7778 - val_loss: 0.4833 - val_accuracy: 0.7868\n",
      "Epoch 92/250\n",
      "4896/4896 [==============================] - 2s 310us/step - loss: 0.4904 - accuracy: 0.7772 - val_loss: 0.5073 - val_accuracy: 0.7515\n",
      "Epoch 93/250\n",
      "4896/4896 [==============================] - 2s 310us/step - loss: 0.4873 - accuracy: 0.7755 - val_loss: 0.4847 - val_accuracy: 0.7929\n",
      "Epoch 94/250\n",
      "4896/4896 [==============================] - 2s 316us/step - loss: 0.4853 - accuracy: 0.7684 - val_loss: 0.4759 - val_accuracy: 0.7822\n",
      "Epoch 95/250\n",
      "4896/4896 [==============================] - 2s 309us/step - loss: 0.4710 - accuracy: 0.7835 - val_loss: 0.4790 - val_accuracy: 0.7669\n",
      "Epoch 96/250\n",
      "4896/4896 [==============================] - 2s 311us/step - loss: 0.4766 - accuracy: 0.7780 - val_loss: 0.4756 - val_accuracy: 0.7745\n",
      "Epoch 97/250\n",
      "4896/4896 [==============================] - 2s 313us/step - loss: 0.4710 - accuracy: 0.7796 - val_loss: 0.4837 - val_accuracy: 0.7822\n",
      "Epoch 98/250\n",
      "4896/4896 [==============================] - 2s 315us/step - loss: 0.4887 - accuracy: 0.7759 - val_loss: 0.4772 - val_accuracy: 0.7991\n",
      "Epoch 99/250\n",
      "4896/4896 [==============================] - 2s 309us/step - loss: 0.4749 - accuracy: 0.7841 - val_loss: 0.4816 - val_accuracy: 0.7684\n",
      "Epoch 100/250\n",
      "4896/4896 [==============================] - 2s 311us/step - loss: 0.4747 - accuracy: 0.7768 - val_loss: 0.4733 - val_accuracy: 0.7699\n",
      "Epoch 101/250\n",
      "4896/4896 [==============================] - 2s 311us/step - loss: 0.4709 - accuracy: 0.7823 - val_loss: 0.4647 - val_accuracy: 0.7991\n",
      "Epoch 102/250\n",
      "4896/4896 [==============================] - 2s 314us/step - loss: 0.4743 - accuracy: 0.7788 - val_loss: 0.4668 - val_accuracy: 0.7868\n",
      "Epoch 103/250\n",
      "4896/4896 [==============================] - 2s 309us/step - loss: 0.4621 - accuracy: 0.7810 - val_loss: 0.4890 - val_accuracy: 0.7822\n",
      "Epoch 104/250\n",
      "4896/4896 [==============================] - 2s 310us/step - loss: 0.4598 - accuracy: 0.7800 - val_loss: 0.4610 - val_accuracy: 0.7914\n",
      "Epoch 105/250\n",
      "4896/4896 [==============================] - 2s 312us/step - loss: 0.4639 - accuracy: 0.7827 - val_loss: 0.5046 - val_accuracy: 0.7791\n",
      "Epoch 106/250\n",
      "4896/4896 [==============================] - 2s 321us/step - loss: 0.4677 - accuracy: 0.7864 - val_loss: 0.4704 - val_accuracy: 0.7791\n",
      "Epoch 107/250\n",
      "4896/4896 [==============================] - 2s 311us/step - loss: 0.4519 - accuracy: 0.7855 - val_loss: 0.4911 - val_accuracy: 0.7776\n",
      "Epoch 108/250\n",
      "4896/4896 [==============================] - 1s 294us/step - loss: 0.4668 - accuracy: 0.7862 - val_loss: 0.4987 - val_accuracy: 0.7500\n",
      "Epoch 109/250\n",
      "4896/4896 [==============================] - 2s 309us/step - loss: 0.4703 - accuracy: 0.7808 - val_loss: 0.4729 - val_accuracy: 0.8006\n",
      "Epoch 110/250\n",
      "4896/4896 [==============================] - 1s 295us/step - loss: 0.4542 - accuracy: 0.7878 - val_loss: 0.4890 - val_accuracy: 0.7546\n",
      "Epoch 111/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4896/4896 [==============================] - 2s 313us/step - loss: 0.4734 - accuracy: 0.7835 - val_loss: 0.4652 - val_accuracy: 0.8037\n",
      "Epoch 112/250\n",
      "4896/4896 [==============================] - 1s 291us/step - loss: 0.4624 - accuracy: 0.7855 - val_loss: 0.4897 - val_accuracy: 0.7730\n",
      "Epoch 113/250\n",
      "4896/4896 [==============================] - 1s 296us/step - loss: 0.4673 - accuracy: 0.7833 - val_loss: 0.4651 - val_accuracy: 0.7899\n",
      "Epoch 114/250\n",
      "4896/4896 [==============================] - 1s 299us/step - loss: 0.4534 - accuracy: 0.7853 - val_loss: 0.4714 - val_accuracy: 0.7960\n",
      "Epoch 115/250\n",
      "4896/4896 [==============================] - 1s 293us/step - loss: 0.4477 - accuracy: 0.7921 - val_loss: 0.4592 - val_accuracy: 0.7868\n",
      "Epoch 116/250\n",
      "4896/4896 [==============================] - 1s 298us/step - loss: 0.4508 - accuracy: 0.7853 - val_loss: 0.4533 - val_accuracy: 0.7761\n",
      "Epoch 117/250\n",
      "4896/4896 [==============================] - 2s 311us/step - loss: 0.4650 - accuracy: 0.7780 - val_loss: 0.4952 - val_accuracy: 0.7807\n",
      "Epoch 118/250\n",
      "4896/4896 [==============================] - 2s 313us/step - loss: 0.4474 - accuracy: 0.7898 - val_loss: 0.4699 - val_accuracy: 0.7960\n",
      "Epoch 119/250\n",
      "4896/4896 [==============================] - 2s 380us/step - loss: 0.4473 - accuracy: 0.7911 - val_loss: 0.4821 - val_accuracy: 0.7730\n",
      "Epoch 120/250\n",
      "4896/4896 [==============================] - 2s 387us/step - loss: 0.4444 - accuracy: 0.7878 - val_loss: 0.4672 - val_accuracy: 0.7868\n",
      "Epoch 121/250\n",
      "4896/4896 [==============================] - 1s 300us/step - loss: 0.4575 - accuracy: 0.7866 - val_loss: 0.4443 - val_accuracy: 0.8006\n",
      "Epoch 122/250\n",
      "4896/4896 [==============================] - 1s 305us/step - loss: 0.4466 - accuracy: 0.7868 - val_loss: 0.4576 - val_accuracy: 0.7669\n",
      "Epoch 123/250\n",
      "4896/4896 [==============================] - 1s 305us/step - loss: 0.4438 - accuracy: 0.7900 - val_loss: 0.4808 - val_accuracy: 0.7791\n",
      "Epoch 124/250\n",
      "4896/4896 [==============================] - 2s 321us/step - loss: 0.4695 - accuracy: 0.7870 - val_loss: 0.4617 - val_accuracy: 0.7929\n",
      "Epoch 125/250\n",
      "4896/4896 [==============================] - 1s 300us/step - loss: 0.4419 - accuracy: 0.7964 - val_loss: 0.4671 - val_accuracy: 0.7607\n",
      "Epoch 126/250\n",
      "4896/4896 [==============================] - 2s 320us/step - loss: 0.4454 - accuracy: 0.7947 - val_loss: 0.4434 - val_accuracy: 0.7761\n",
      "Epoch 127/250\n",
      "4896/4896 [==============================] - 2s 307us/step - loss: 0.4347 - accuracy: 0.7951 - val_loss: 0.4636 - val_accuracy: 0.7745\n",
      "Epoch 128/250\n",
      "4896/4896 [==============================] - 1s 295us/step - loss: 0.4426 - accuracy: 0.7947 - val_loss: 0.4708 - val_accuracy: 0.7929\n",
      "Epoch 129/250\n",
      "4896/4896 [==============================] - 2s 308us/step - loss: 0.4405 - accuracy: 0.7984 - val_loss: 0.4714 - val_accuracy: 0.7761\n",
      "Epoch 130/250\n",
      "4896/4896 [==============================] - 2s 307us/step - loss: 0.4355 - accuracy: 0.7978 - val_loss: 0.4360 - val_accuracy: 0.8144\n",
      "Epoch 131/250\n",
      "4896/4896 [==============================] - 1s 306us/step - loss: 0.4359 - accuracy: 0.7964 - val_loss: 0.4592 - val_accuracy: 0.7561\n",
      "Epoch 132/250\n",
      "4896/4896 [==============================] - 1s 300us/step - loss: 0.4463 - accuracy: 0.7862 - val_loss: 0.4816 - val_accuracy: 0.7715\n",
      "Epoch 133/250\n",
      "4896/4896 [==============================] - 2s 317us/step - loss: 0.4451 - accuracy: 0.7876 - val_loss: 0.4664 - val_accuracy: 0.7761\n",
      "Epoch 134/250\n",
      "4896/4896 [==============================] - 2s 311us/step - loss: 0.4378 - accuracy: 0.7972 - val_loss: 0.4693 - val_accuracy: 0.7883\n",
      "Epoch 135/250\n",
      "4896/4896 [==============================] - 2s 309us/step - loss: 0.4329 - accuracy: 0.7898 - val_loss: 0.4329 - val_accuracy: 0.8083\n",
      "Epoch 136/250\n",
      "4896/4896 [==============================] - 1s 302us/step - loss: 0.4212 - accuracy: 0.7992 - val_loss: 0.4663 - val_accuracy: 0.7853\n",
      "Epoch 137/250\n",
      "4896/4896 [==============================] - 1s 305us/step - loss: 0.4400 - accuracy: 0.8004 - val_loss: 0.4364 - val_accuracy: 0.7868\n",
      "Epoch 138/250\n",
      "4896/4896 [==============================] - 1s 302us/step - loss: 0.4300 - accuracy: 0.8009 - val_loss: 0.4446 - val_accuracy: 0.7730\n",
      "Epoch 139/250\n",
      "4896/4896 [==============================] - 1s 305us/step - loss: 0.4281 - accuracy: 0.7974 - val_loss: 0.4777 - val_accuracy: 0.7807\n",
      "Epoch 140/250\n",
      "4896/4896 [==============================] - 1s 290us/step - loss: 0.4314 - accuracy: 0.8031 - val_loss: 0.4549 - val_accuracy: 0.8113\n",
      "Epoch 141/250\n",
      "4896/4896 [==============================] - 1s 294us/step - loss: 0.4415 - accuracy: 0.7900 - val_loss: 0.4533 - val_accuracy: 0.7991\n",
      "Epoch 142/250\n",
      "4896/4896 [==============================] - 1s 292us/step - loss: 0.4093 - accuracy: 0.8054 - val_loss: 0.4351 - val_accuracy: 0.7991\n",
      "Epoch 143/250\n",
      "4896/4896 [==============================] - 1s 290us/step - loss: 0.4211 - accuracy: 0.8017 - val_loss: 0.4500 - val_accuracy: 0.7883\n",
      "Epoch 144/250\n",
      "4896/4896 [==============================] - 1s 292us/step - loss: 0.4343 - accuracy: 0.7984 - val_loss: 0.4447 - val_accuracy: 0.8113\n",
      "Epoch 145/250\n",
      "4896/4896 [==============================] - 1s 297us/step - loss: 0.4146 - accuracy: 0.8035 - val_loss: 0.4380 - val_accuracy: 0.8052\n",
      "Epoch 146/250\n",
      "4896/4896 [==============================] - 1s 302us/step - loss: 0.4384 - accuracy: 0.8011 - val_loss: 0.4543 - val_accuracy: 0.7822\n",
      "Epoch 147/250\n",
      "4896/4896 [==============================] - 1s 299us/step - loss: 0.4248 - accuracy: 0.8054 - val_loss: 0.4234 - val_accuracy: 0.8206\n",
      "Epoch 148/250\n",
      "4896/4896 [==============================] - 1s 299us/step - loss: 0.4199 - accuracy: 0.8041 - val_loss: 0.4663 - val_accuracy: 0.7715\n",
      "Epoch 149/250\n",
      "4896/4896 [==============================] - 2s 459us/step - loss: 0.4149 - accuracy: 0.8078 - val_loss: 0.4382 - val_accuracy: 0.7807\n",
      "Epoch 150/250\n",
      "4896/4896 [==============================] - 2s 355us/step - loss: 0.4313 - accuracy: 0.7990 - val_loss: 0.4339 - val_accuracy: 0.7991\n",
      "Epoch 151/250\n",
      "4896/4896 [==============================] - 1s 303us/step - loss: 0.4268 - accuracy: 0.8007 - val_loss: 0.4392 - val_accuracy: 0.8067\n",
      "Epoch 152/250\n",
      "4896/4896 [==============================] - 2s 355us/step - loss: 0.4172 - accuracy: 0.8060 - val_loss: 0.4669 - val_accuracy: 0.7699\n",
      "Epoch 153/250\n",
      "4896/4896 [==============================] - 2s 310us/step - loss: 0.4395 - accuracy: 0.7935 - val_loss: 0.4466 - val_accuracy: 0.8083\n",
      "Epoch 154/250\n",
      "4896/4896 [==============================] - 2s 314us/step - loss: 0.4319 - accuracy: 0.7988 - val_loss: 0.4353 - val_accuracy: 0.7791\n",
      "Epoch 155/250\n",
      "4896/4896 [==============================] - 2s 341us/step - loss: 0.4206 - accuracy: 0.8098 - val_loss: 0.4280 - val_accuracy: 0.7914\n",
      "Epoch 156/250\n",
      "4896/4896 [==============================] - 2s 322us/step - loss: 0.4300 - accuracy: 0.8070 - val_loss: 0.4445 - val_accuracy: 0.7899\n",
      "Epoch 157/250\n",
      "4896/4896 [==============================] - 2s 328us/step - loss: 0.4096 - accuracy: 0.8056 - val_loss: 0.4135 - val_accuracy: 0.7975\n",
      "Epoch 158/250\n",
      "4896/4896 [==============================] - 2s 316us/step - loss: 0.4077 - accuracy: 0.8115 - val_loss: 0.4608 - val_accuracy: 0.8006\n",
      "Epoch 159/250\n",
      "4896/4896 [==============================] - 1s 303us/step - loss: 0.4118 - accuracy: 0.8096 - val_loss: 0.4261 - val_accuracy: 0.8083\n",
      "Epoch 160/250\n",
      "4896/4896 [==============================] - 1s 298us/step - loss: 0.4129 - accuracy: 0.8115 - val_loss: 0.4652 - val_accuracy: 0.8052\n",
      "Epoch 161/250\n",
      "4896/4896 [==============================] - 1s 298us/step - loss: 0.4055 - accuracy: 0.8084 - val_loss: 0.4585 - val_accuracy: 0.7653\n",
      "Epoch 162/250\n",
      "4896/4896 [==============================] - 2s 312us/step - loss: 0.4040 - accuracy: 0.8127 - val_loss: 0.4189 - val_accuracy: 0.7975\n",
      "Epoch 163/250\n",
      "4896/4896 [==============================] - 1s 301us/step - loss: 0.4133 - accuracy: 0.8135 - val_loss: 0.4102 - val_accuracy: 0.8144\n",
      "Epoch 164/250\n",
      "4896/4896 [==============================] - 2s 316us/step - loss: 0.3981 - accuracy: 0.8190 - val_loss: 0.4651 - val_accuracy: 0.7960\n",
      "Epoch 165/250\n",
      "4896/4896 [==============================] - 2s 335us/step - loss: 0.4050 - accuracy: 0.8078 - val_loss: 0.4196 - val_accuracy: 0.8267\n",
      "Epoch 166/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4896/4896 [==============================] - 1s 298us/step - loss: 0.4055 - accuracy: 0.8011 - val_loss: 0.4131 - val_accuracy: 0.8129\n",
      "Epoch 167/250\n",
      "4896/4896 [==============================] - 2s 318us/step - loss: 0.4089 - accuracy: 0.8168 - val_loss: 0.4206 - val_accuracy: 0.8052\n",
      "Epoch 168/250\n",
      "4896/4896 [==============================] - 2s 313us/step - loss: 0.4087 - accuracy: 0.8094 - val_loss: 0.4297 - val_accuracy: 0.8282\n",
      "Epoch 169/250\n",
      "4896/4896 [==============================] - 1s 305us/step - loss: 0.4034 - accuracy: 0.8096 - val_loss: 0.4589 - val_accuracy: 0.7807\n",
      "Epoch 170/250\n",
      "4896/4896 [==============================] - 1s 296us/step - loss: 0.4118 - accuracy: 0.8070 - val_loss: 0.4373 - val_accuracy: 0.7960\n",
      "Epoch 171/250\n",
      "4896/4896 [==============================] - 1s 296us/step - loss: 0.4032 - accuracy: 0.8098 - val_loss: 0.4112 - val_accuracy: 0.8144\n",
      "Epoch 172/250\n",
      "4896/4896 [==============================] - 1s 286us/step - loss: 0.4002 - accuracy: 0.8121 - val_loss: 0.4114 - val_accuracy: 0.7791\n",
      "Epoch 173/250\n",
      "4896/4896 [==============================] - 1s 289us/step - loss: 0.3964 - accuracy: 0.8174 - val_loss: 0.4063 - val_accuracy: 0.8113\n",
      "Epoch 174/250\n",
      "4896/4896 [==============================] - 1s 291us/step - loss: 0.3940 - accuracy: 0.8150 - val_loss: 0.4043 - val_accuracy: 0.8328\n",
      "Epoch 175/250\n",
      "4896/4896 [==============================] - 1s 292us/step - loss: 0.4027 - accuracy: 0.8139 - val_loss: 0.4322 - val_accuracy: 0.7853\n",
      "Epoch 176/250\n",
      "4896/4896 [==============================] - 1s 294us/step - loss: 0.3996 - accuracy: 0.8178 - val_loss: 0.4349 - val_accuracy: 0.8098\n",
      "Epoch 177/250\n",
      "4896/4896 [==============================] - 1s 288us/step - loss: 0.3900 - accuracy: 0.8250 - val_loss: 0.4257 - val_accuracy: 0.8236\n",
      "Epoch 178/250\n",
      "4896/4896 [==============================] - 1s 297us/step - loss: 0.3876 - accuracy: 0.8192 - val_loss: 0.3984 - val_accuracy: 0.8144\n",
      "Epoch 179/250\n",
      "4896/4896 [==============================] - 2s 308us/step - loss: 0.3933 - accuracy: 0.8199 - val_loss: 0.4104 - val_accuracy: 0.8113\n",
      "Epoch 180/250\n",
      "4896/4896 [==============================] - 2s 306us/step - loss: 0.3920 - accuracy: 0.8113 - val_loss: 0.4346 - val_accuracy: 0.8067\n",
      "Epoch 181/250\n",
      "4896/4896 [==============================] - 1s 304us/step - loss: 0.3958 - accuracy: 0.8170 - val_loss: 0.4227 - val_accuracy: 0.8083\n",
      "Epoch 182/250\n",
      "4896/4896 [==============================] - 2s 427us/step - loss: 0.4030 - accuracy: 0.8168 - val_loss: 0.4118 - val_accuracy: 0.8344\n",
      "Epoch 183/250\n",
      "4896/4896 [==============================] - 2s 439us/step - loss: 0.3973 - accuracy: 0.8129 - val_loss: 0.4713 - val_accuracy: 0.7745\n",
      "Epoch 184/250\n",
      "4896/4896 [==============================] - 2s 432us/step - loss: 0.4074 - accuracy: 0.8123 - val_loss: 0.4031 - val_accuracy: 0.8006\n",
      "Epoch 185/250\n",
      "4896/4896 [==============================] - 2s 413us/step - loss: 0.3840 - accuracy: 0.8248 - val_loss: 0.4122 - val_accuracy: 0.8144\n",
      "Epoch 186/250\n",
      "4896/4896 [==============================] - 2s 420us/step - loss: 0.3905 - accuracy: 0.8209 - val_loss: 0.4123 - val_accuracy: 0.8252\n",
      "Epoch 187/250\n",
      "4896/4896 [==============================] - 2s 487us/step - loss: 0.3856 - accuracy: 0.8170 - val_loss: 0.4047 - val_accuracy: 0.8083\n",
      "Epoch 188/250\n",
      "4896/4896 [==============================] - 2s 479us/step - loss: 0.3892 - accuracy: 0.8188 - val_loss: 0.4965 - val_accuracy: 0.7745\n",
      "Epoch 189/250\n",
      "4896/4896 [==============================] - 3s 524us/step - loss: 0.3973 - accuracy: 0.8121 - val_loss: 0.4200 - val_accuracy: 0.8021\n",
      "Epoch 190/250\n",
      "4896/4896 [==============================] - 2s 483us/step - loss: 0.3843 - accuracy: 0.8152 - val_loss: 0.4076 - val_accuracy: 0.7960\n",
      "Epoch 191/250\n",
      "4896/4896 [==============================] - 2s 349us/step - loss: 0.3900 - accuracy: 0.8203 - val_loss: 0.4074 - val_accuracy: 0.8344\n",
      "Epoch 192/250\n",
      "4896/4896 [==============================] - 2s 461us/step - loss: 0.3912 - accuracy: 0.8154 - val_loss: 0.3841 - val_accuracy: 0.8313\n",
      "Epoch 193/250\n",
      "4896/4896 [==============================] - 2s 437us/step - loss: 0.3795 - accuracy: 0.8194 - val_loss: 0.3998 - val_accuracy: 0.8160\n",
      "Epoch 194/250\n",
      "4896/4896 [==============================] - 2s 407us/step - loss: 0.3899 - accuracy: 0.8139 - val_loss: 0.3977 - val_accuracy: 0.8298\n",
      "Epoch 195/250\n",
      "4896/4896 [==============================] - 1s 295us/step - loss: 0.3910 - accuracy: 0.8150 - val_loss: 0.4393 - val_accuracy: 0.7837\n",
      "Epoch 196/250\n",
      "4896/4896 [==============================] - 1s 298us/step - loss: 0.3910 - accuracy: 0.8186 - val_loss: 0.4278 - val_accuracy: 0.8129\n",
      "Epoch 197/250\n",
      "4896/4896 [==============================] - 1s 301us/step - loss: 0.3869 - accuracy: 0.8205 - val_loss: 0.3849 - val_accuracy: 0.8313\n",
      "Epoch 198/250\n",
      "4896/4896 [==============================] - 2s 339us/step - loss: 0.3714 - accuracy: 0.8286 - val_loss: 0.3747 - val_accuracy: 0.8160\n",
      "Epoch 199/250\n",
      "4896/4896 [==============================] - 2s 391us/step - loss: 0.3761 - accuracy: 0.8260 - val_loss: 0.3988 - val_accuracy: 0.8113\n",
      "Epoch 200/250\n",
      "4896/4896 [==============================] - 2s 320us/step - loss: 0.3775 - accuracy: 0.8184 - val_loss: 0.4108 - val_accuracy: 0.8067\n",
      "Epoch 201/250\n",
      "4896/4896 [==============================] - 2s 316us/step - loss: 0.3794 - accuracy: 0.8243 - val_loss: 0.4024 - val_accuracy: 0.8298\n",
      "Epoch 202/250\n",
      "4896/4896 [==============================] - 2s 320us/step - loss: 0.3768 - accuracy: 0.8262 - val_loss: 0.3836 - val_accuracy: 0.8436\n",
      "Epoch 203/250\n",
      "4896/4896 [==============================] - 2s 310us/step - loss: 0.3977 - accuracy: 0.8135 - val_loss: 0.3897 - val_accuracy: 0.8282\n",
      "Epoch 204/250\n",
      "4896/4896 [==============================] - 1s 298us/step - loss: 0.3726 - accuracy: 0.8182 - val_loss: 0.3992 - val_accuracy: 0.8252\n",
      "Epoch 205/250\n",
      "4896/4896 [==============================] - 1s 305us/step - loss: 0.3756 - accuracy: 0.8262 - val_loss: 0.4087 - val_accuracy: 0.8098\n",
      "Epoch 206/250\n",
      "4896/4896 [==============================] - 1s 287us/step - loss: 0.3751 - accuracy: 0.8194 - val_loss: 0.4132 - val_accuracy: 0.8175\n",
      "Epoch 207/250\n",
      "4896/4896 [==============================] - 1s 300us/step - loss: 0.3686 - accuracy: 0.8311 - val_loss: 0.4055 - val_accuracy: 0.8052\n",
      "Epoch 208/250\n",
      "4896/4896 [==============================] - 1s 291us/step - loss: 0.3835 - accuracy: 0.8233 - val_loss: 0.3770 - val_accuracy: 0.8512\n",
      "Epoch 209/250\n",
      "4896/4896 [==============================] - 2s 317us/step - loss: 0.3704 - accuracy: 0.8229 - val_loss: 0.3866 - val_accuracy: 0.8359\n",
      "Epoch 210/250\n",
      "4896/4896 [==============================] - 1s 293us/step - loss: 0.3680 - accuracy: 0.8288 - val_loss: 0.4195 - val_accuracy: 0.8006\n",
      "Epoch 211/250\n",
      "4896/4896 [==============================] - 2s 310us/step - loss: 0.3690 - accuracy: 0.8288 - val_loss: 0.3983 - val_accuracy: 0.8313\n",
      "Epoch 212/250\n",
      "4896/4896 [==============================] - 2s 314us/step - loss: 0.3797 - accuracy: 0.8223 - val_loss: 0.4118 - val_accuracy: 0.8067\n",
      "Epoch 213/250\n",
      "4896/4896 [==============================] - 2s 317us/step - loss: 0.3722 - accuracy: 0.8297 - val_loss: 0.3960 - val_accuracy: 0.8206\n",
      "Epoch 214/250\n",
      "4896/4896 [==============================] - 2s 310us/step - loss: 0.3690 - accuracy: 0.8215 - val_loss: 0.4167 - val_accuracy: 0.8175\n",
      "Epoch 215/250\n",
      "4896/4896 [==============================] - 2s 332us/step - loss: 0.3776 - accuracy: 0.8258 - val_loss: 0.3853 - val_accuracy: 0.8405\n",
      "Epoch 216/250\n",
      "4896/4896 [==============================] - 2s 334us/step - loss: 0.3795 - accuracy: 0.8297 - val_loss: 0.3816 - val_accuracy: 0.8282\n",
      "Epoch 217/250\n",
      "4896/4896 [==============================] - 2s 323us/step - loss: 0.3841 - accuracy: 0.8227 - val_loss: 0.3813 - val_accuracy: 0.8144\n",
      "Epoch 218/250\n",
      "4896/4896 [==============================] - 2s 318us/step - loss: 0.3706 - accuracy: 0.8327 - val_loss: 0.3967 - val_accuracy: 0.8221\n",
      "Epoch 219/250\n",
      "4896/4896 [==============================] - 2s 311us/step - loss: 0.3649 - accuracy: 0.8297 - val_loss: 0.3903 - val_accuracy: 0.8267\n",
      "Epoch 220/250\n",
      "4896/4896 [==============================] - 2s 351us/step - loss: 0.3690 - accuracy: 0.8286 - val_loss: 0.3959 - val_accuracy: 0.8190\n",
      "Epoch 221/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4896/4896 [==============================] - 1s 287us/step - loss: 0.3676 - accuracy: 0.8301 - val_loss: 0.4221 - val_accuracy: 0.8206\n",
      "Epoch 222/250\n",
      "4896/4896 [==============================] - 1s 304us/step - loss: 0.3630 - accuracy: 0.8307 - val_loss: 0.3702 - val_accuracy: 0.8282\n",
      "Epoch 223/250\n",
      "4896/4896 [==============================] - 1s 295us/step - loss: 0.3759 - accuracy: 0.8203 - val_loss: 0.3898 - val_accuracy: 0.8144\n",
      "Epoch 224/250\n",
      "4896/4896 [==============================] - 1s 296us/step - loss: 0.3763 - accuracy: 0.8266 - val_loss: 0.3995 - val_accuracy: 0.8221\n",
      "Epoch 225/250\n",
      "4896/4896 [==============================] - 1s 288us/step - loss: 0.3651 - accuracy: 0.8256 - val_loss: 0.3712 - val_accuracy: 0.8359\n",
      "Epoch 226/250\n",
      "4896/4896 [==============================] - 1s 300us/step - loss: 0.3677 - accuracy: 0.8288 - val_loss: 0.3873 - val_accuracy: 0.8129\n",
      "Epoch 227/250\n",
      "4896/4896 [==============================] - 1s 302us/step - loss: 0.3652 - accuracy: 0.8329 - val_loss: 0.4018 - val_accuracy: 0.8298\n",
      "Epoch 228/250\n",
      "4896/4896 [==============================] - 1s 288us/step - loss: 0.3583 - accuracy: 0.8391 - val_loss: 0.3824 - val_accuracy: 0.8206\n",
      "Epoch 229/250\n",
      "4896/4896 [==============================] - 1s 306us/step - loss: 0.3569 - accuracy: 0.8327 - val_loss: 0.3797 - val_accuracy: 0.8466\n",
      "Epoch 230/250\n",
      "4896/4896 [==============================] - 1s 292us/step - loss: 0.3526 - accuracy: 0.8309 - val_loss: 0.3596 - val_accuracy: 0.8482\n",
      "Epoch 231/250\n",
      "4896/4896 [==============================] - 2s 339us/step - loss: 0.3639 - accuracy: 0.8288 - val_loss: 0.4086 - val_accuracy: 0.8129\n",
      "Epoch 232/250\n",
      "4896/4896 [==============================] - 1s 302us/step - loss: 0.3571 - accuracy: 0.8290 - val_loss: 0.3842 - val_accuracy: 0.8160\n",
      "Epoch 233/250\n",
      "4896/4896 [==============================] - 2s 328us/step - loss: 0.3577 - accuracy: 0.8299 - val_loss: 0.4151 - val_accuracy: 0.7975\n",
      "Epoch 234/250\n",
      "4896/4896 [==============================] - 2s 331us/step - loss: 0.3687 - accuracy: 0.8262 - val_loss: 0.3914 - val_accuracy: 0.8267\n",
      "Epoch 235/250\n",
      "4896/4896 [==============================] - 2s 335us/step - loss: 0.3780 - accuracy: 0.8268 - val_loss: 0.3627 - val_accuracy: 0.8420\n",
      "Epoch 236/250\n",
      "4896/4896 [==============================] - 2s 339us/step - loss: 0.3547 - accuracy: 0.8297 - val_loss: 0.3822 - val_accuracy: 0.8267\n",
      "Epoch 237/250\n",
      "4896/4896 [==============================] - 2s 307us/step - loss: 0.3548 - accuracy: 0.8352 - val_loss: 0.3936 - val_accuracy: 0.8067\n",
      "Epoch 238/250\n",
      "4896/4896 [==============================] - 1s 292us/step - loss: 0.3526 - accuracy: 0.8309 - val_loss: 0.3570 - val_accuracy: 0.8574\n",
      "Epoch 239/250\n",
      "4896/4896 [==============================] - 1s 288us/step - loss: 0.3661 - accuracy: 0.8321 - val_loss: 0.3867 - val_accuracy: 0.8313\n",
      "Epoch 240/250\n",
      "4896/4896 [==============================] - 2s 359us/step - loss: 0.3557 - accuracy: 0.8378 - val_loss: 0.3896 - val_accuracy: 0.8021\n",
      "Epoch 241/250\n",
      "4896/4896 [==============================] - 2s 312us/step - loss: 0.3574 - accuracy: 0.8337 - val_loss: 0.3692 - val_accuracy: 0.8390\n",
      "Epoch 242/250\n",
      "4896/4896 [==============================] - 1s 300us/step - loss: 0.3608 - accuracy: 0.8276 - val_loss: 0.3750 - val_accuracy: 0.8344\n",
      "Epoch 243/250\n",
      "4896/4896 [==============================] - 2s 465us/step - loss: 0.3456 - accuracy: 0.8399 - val_loss: 0.3507 - val_accuracy: 0.8420\n",
      "Epoch 244/250\n",
      "4896/4896 [==============================] - 2s 431us/step - loss: 0.3568 - accuracy: 0.8305 - val_loss: 0.3708 - val_accuracy: 0.8405\n",
      "Epoch 245/250\n",
      "4896/4896 [==============================] - 2s 341us/step - loss: 0.3625 - accuracy: 0.8243 - val_loss: 0.3696 - val_accuracy: 0.8313\n",
      "Epoch 246/250\n",
      "4896/4896 [==============================] - 2s 327us/step - loss: 0.3479 - accuracy: 0.8395 - val_loss: 0.3719 - val_accuracy: 0.8175\n",
      "Epoch 247/250\n",
      "4896/4896 [==============================] - 2s 353us/step - loss: 0.3504 - accuracy: 0.8350 - val_loss: 0.3766 - val_accuracy: 0.8267\n",
      "Epoch 248/250\n",
      "4896/4896 [==============================] - 2s 355us/step - loss: 0.3501 - accuracy: 0.8358 - val_loss: 0.4007 - val_accuracy: 0.8221\n",
      "Epoch 249/250\n",
      "4896/4896 [==============================] - 1s 301us/step - loss: 0.3528 - accuracy: 0.8329 - val_loss: 0.4228 - val_accuracy: 0.8313\n",
      "Epoch 250/250\n",
      "4896/4896 [==============================] - 1s 300us/step - loss: 0.3639 - accuracy: 0.8286 - val_loss: 0.3764 - val_accuracy: 0.8328\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 250\n",
    "\n",
    "H = classifier.fit(x_train, lab_red_train,\n",
    "                  epochs = EPOCHS,\n",
    "                  batch_size = 128,\n",
    "                  shuffle = True,\n",
    "                  validation_data=(x_val, lab_red_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the network - display netowork stats and save plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training loss and accuracy for each epoch\n",
    "N = np.arange(0,EPOCHS)\n",
    "plt.figure()\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(N, H.history[\"accuracy\"], label=\"train_accuracy\")\n",
    "plt.plot(N, H.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.title(\"Predicting Redshift\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(\"training_perf_250_arch_03.0_pred_redshift_with_encoder.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save(\"keras_arch_03.0_with_encoder_redshift_predict.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(980, 17) (980, 17)\n"
     ]
    }
   ],
   "source": [
    "pred = classifier.predict(x_test)\n",
    "print(pred.shape, lab_red_test.shape)\n",
    "l = len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "right,wrong = 0,0\n",
    "for i in range(len(pred)):\n",
    "    if pred[i].all()==lab_red_test[i].all(): right+=1\n",
    "    else: wrong+=1\n",
    "count = right+wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage correctly classified\n",
      " 100.0\n"
     ]
    }
   ],
   "source": [
    "print(\"percentage correctly classified\\n\",\n",
    "     100.0*float(right)/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
