{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to avoid the problem I had while training the autoencoder, which is that I would have to re-shuffle the training and validation set everytime I closed the notebook, so Instead I will do that once here and save the shuffled data + labels as .npy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load redshift data labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['preprocessing.ipynb',\n",
       " 'CNN1_fixed_esc_frac_0070_redshift_train_with_autoencoder.ipynb',\n",
       " 'esc_frac_0070_labels.npy',\n",
       " 'CNN1_fixed_esc_frac_0070_redshift_train_no_encoder.ipynb',\n",
       " 'esc_frac_0070_data.npy',\n",
       " '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3400, 200, 200)\n",
      "(3400,)\n"
     ]
    }
   ],
   "source": [
    "labels_all = np.load(\"esc_frac_0070_labels.npy\")\n",
    "images = np.load(\"esc_frac_0070_data.npy\")\n",
    "\n",
    "print(images.shape)\n",
    "print(labels_all.shape)\n",
    "\n",
    "images = list(images)\n",
    "labels_all = list(labels_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_images = []\n",
    "shuffled_labels_all = []\n",
    "while images:\n",
    "    i = random.randrange(len(images))\n",
    "    shuffled_images.append(images[i])\n",
    "    del images[i]\n",
    "    shuffled_labels_all.append(labels_all[i])\n",
    "    del labels_all[i]\n",
    "    \n",
    "images = np.array(shuffled_images[:])\n",
    "labels_all = np.array(shuffled_labels_all[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3400, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### while im here i might aswell make the labels so that the model can read them... and do the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max :  0.9531142\n",
      "min :  0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3400, 200, 200)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalizes images\n",
    "images_n = images / 70.0 # n for normalized\n",
    "print(\"max : \", np.max(images_n))\n",
    "print(\"min : \", np.min(images_n))\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape the images for feeding through the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_reshape = np.array(images_n[:])\n",
    "im_reshape = np.expand_dims(im_reshape, axis = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the shape (3400, 200, 200, 1)\n"
     ]
    }
   ],
   "source": [
    "im_reshape = np.array(im_reshape)\n",
    "print(\"this is the shape\", im_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.5\n",
      "8.5\n",
      "13.0\n",
      "8.5\n",
      "10.5\n",
      "12.0\n",
      "11.5\n",
      "6.0\n",
      "6.5\n",
      "8.0\n",
      "6.5\n",
      "7.5\n",
      "10.5\n",
      "6.0\n",
      "8.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(15):\n",
    "    print(labels_all[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format the labels so the network can read them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5, 9.0, 9.5, 10.0, 10.5, 11.0, 11.5, 12.0, 12.5, 13.0] \n",
      "There are 17 labels. So the want 17 classes\n"
     ]
    }
   ],
   "source": [
    "# display the labels\n",
    "l = []\n",
    "for i in labels_all:\n",
    "    if i not in l: l.append(i)\n",
    "l.sort()\n",
    "print(l, \"\\nThere are\", len(l), \"labels. So the want\",\n",
    "     len(l), \"classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_labels shape = (3400, 17) \n",
      "\n",
      "First 3 entries:\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# define the train labels in len 17 arrays\n",
    "labels=[]\n",
    "for i in labels_all:\n",
    "    arr = np.zeros(len(l))\n",
    "    index = l.index(i)\n",
    "    arr[index] = 1\n",
    "    labels.append(arr[:])\n",
    "    \n",
    "labels = np.array(labels)\n",
    "print(\"train_labels shape =\", labels.shape,\n",
    "     \"\\n\\nFirst 3 entries:\")\n",
    "print(labels[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max : 0.9531142\n",
      "min : 0.0\n"
     ]
    }
   ],
   "source": [
    "# normalize images\n",
    "images_n = images / 70.0 # for some reason this one is 40...\n",
    "# it's the data not me\n",
    "print(\"max :\", np.max(images_n))\n",
    "print(\"min :\", np.min(images_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## augmentation dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the shape (3400, 200, 200, 1)\n"
     ]
    }
   ],
   "source": [
    "im_reshape = np.array(images_n[:])\n",
    "im_reshape = np.expand_dims(im_reshape, axis=3)\n",
    "im_reshape = np.array(im_reshape)\n",
    "print(\"this is the shape\", im_reshape.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = [0.75,0.85]\n",
    "cut1,cut2 = int(len(im_reshape)*ratios[0]),int(len(im_reshape)*ratios[1])\n",
    "images_train = im_reshape[:cut1]\n",
    "images_val = im_reshape[cut1:cut2]\n",
    "images_test = im_reshape[cut2:]\n",
    "labels_train = labels[:cut1]\n",
    "labels_val = labels[cut1:cut2]\n",
    "labels_test = labels[cut2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2550, 200, 200, 1)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"esc0070_data_train.npy\", images_train)\n",
    "np.save(\"esc0070_data_val.npy\", images_val)\n",
    "np.save(\"esc0070_data_test.npy\", images_test)\n",
    "np.save(\"esc0070_labels_train.npy\", labels_train)\n",
    "np.save(\"esc0070_labels_val.npy\", labels_val)\n",
    "np.save(\"esc0070_labels_test.npy\", labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
